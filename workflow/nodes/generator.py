"""
ì‘ë‹µ ìƒì„± ë…¸ë“œ
- LLMì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import logging
from typing import Dict, Any

from workflow.state import AgentState, ChatMessage
from workflow.nodes.merger import build_merged_context
from llm.llm_client import get_llm_client

logger = logging.getLogger(__name__)


def _is_concept_question(query: str, query_intent: str) -> bool:
    """ê°œë… ì„¤ëª… ìš”ì²­ì¸ì§€ í™•ì¸

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        query_intent: ë¶„ì„ëœ ì§ˆë¬¸ ì˜ë„

    Returns:
        ê°œë… ì„¤ëª… ìš”ì²­ ì—¬ë¶€
    """
    concept_patterns = ["ë€?", "ì´ë€?", "ë­ì•¼", "ë¬´ì—‡", "ì„¤ëª…í•´", "ë­”ê°€ìš”", "ë­ì—ìš”", "ì´ë€", "ì´ ë­"]
    intent_keywords = ["ê°œë…", "ì„¤ëª…", "ì •ì˜", "ì˜ë¯¸"]

    return (
        any(p in query for p in concept_patterns) or
        any(k in query_intent for k in intent_keywords)
    )


def _is_context_meaningful(context: str) -> bool:
    """ì»¨í…ìŠ¤íŠ¸ê°€ ì˜ë¯¸ ìˆëŠ” ì •ë³´ì¸ì§€ í™•ì¸

    ìˆ«ì IDë§Œ ìˆê³  ì‹¤ì œ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ê°ì§€

    Args:
        context: ë³‘í•©ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´

    Returns:
        ì˜ë¯¸ ìˆëŠ” ì •ë³´ í¬í•¨ ì—¬ë¶€
    """
    if not context or context == "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
        return False

    # ë‚´ìš©ì´ ìˆëŠ” ì¤„ ìˆ˜ í™•ì¸ (IDë§Œ ìˆëŠ” ì¤„ ì œì™¸)
    lines = [l.strip() for l in context.split('\n') if l.strip()]

    # ì˜ë¯¸ ìˆëŠ” ì¤„: 30ì ì´ìƒì´ê³ , ìˆ«ì/íŒŒì´í”„ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§€ì§€ ì•Šì€ ì¤„
    content_lines = []
    for line in lines:
        # í…Œì´ë¸” êµ¬ë¶„ì„  ì œì™¸
        if line.replace('-', '').replace('|', '').strip() == '':
            continue
        # ìˆœìˆ˜ ìˆ«ì ID ì¤„ ì œì™¸
        cleaned = line.replace('|', '').replace('[', '').replace(']', '').strip()
        if cleaned.isdigit():
            continue
        # 30ì ì´ìƒì˜ ì‹¤ì œ ë‚´ìš©ì´ ìˆëŠ” ì¤„
        if len(line) > 30:
            content_lines.append(line)

    return len(content_lines) >= 3


def _build_statistics_context(es_statistics: dict, query: str) -> str:
    """Phase 99.5: ES í†µê³„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

    Args:
        es_statistics: ES entity_statistics() ê²°ê³¼
            {
                "patent": {"total": 1234, "buckets": [{"key": "2024", "count": 100}, ...]},
                "project": {...}
            }
        query: ì‚¬ìš©ì ì§ˆë¬¸ (ì»¨í…ìŠ¤íŠ¸ìš©)

    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ í†µê³„ ì»¨í…ìŠ¤íŠ¸
    """
    lines = []

    for entity_type, stats in es_statistics.items():
        if stats.get("error"):
            lines.append(f"### {entity_type} í†µê³„ ì˜¤ë¥˜: {stats.get('error')}")
            continue

        total = stats.get("total", 0)
        period = stats.get("period", "")
        buckets = stats.get("buckets", [])

        # ì—”í‹°í‹° ë¼ë²¨ ë³€í™˜
        entity_labels = {
            "patent": "íŠ¹í—ˆ",
            "project": "ì—°êµ¬ê³¼ì œ",
        }
        label = entity_labels.get(entity_type, entity_type)

        lines.append(f"### {label} ì—°ë„ë³„ í†µê³„ ({period})")
        lines.append(f"- ì´ {total:,}ê±´")
        lines.append("")

        if buckets:
            # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìƒì„±
            lines.append("| ì—°ë„ | ê±´ìˆ˜ |")
            lines.append("|------|------|")

            # ì—°ë„ìˆœ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
            sorted_buckets = sorted(buckets, key=lambda x: x["key"], reverse=True)

            for bucket in sorted_buckets:
                year = bucket.get("key", "")
                count = bucket.get("count", 0)
                lines.append(f"| {year} | {count:,} |")

            lines.append("")

            # ê°„ë‹¨í•œ í†µê³„ ê³„ì‚°
            counts = [b["count"] for b in sorted_buckets if b["count"] > 0]
            if len(counts) >= 2:
                recent_3 = counts[:3] if len(counts) >= 3 else counts
                older_3 = counts[3:6] if len(counts) >= 6 else counts[len(recent_3):]

                recent_avg = sum(recent_3) / len(recent_3) if recent_3 else 0
                older_avg = sum(older_3) / len(older_3) if older_3 else 0

                lines.append(f"**ìš”ì•½ í†µê³„:**")
                lines.append(f"- ìµœê·¼ {len(recent_3)}ë…„ í‰ê· : {recent_avg:,.0f}ê±´")
                if older_avg > 0:
                    change = ((recent_avg - older_avg) / older_avg) * 100
                    lines.append(f"- ì´ì „ {len(older_3)}ë…„ í‰ê· : {older_avg:,.0f}ê±´")
                    lines.append(f"- ë³€í™”ìœ¨: {change:+.1f}%")
                lines.append("")

    return "\n".join(lines)


def _build_crosstab_context(es_statistics: dict, query: str) -> str:
    """Phase 99.6: í¬ë¡œìŠ¤íƒ­ í†µê³„ë¥¼ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜

    Args:
        es_statistics: ES nested aggregation ê²°ê³¼
            {
                "patent": {
                    "crosstab_type": "applicant_year",
                    "years": [2019, 2020, ...],
                    "rows": [{"rank": 1, "name": "...", "nationality": "KR", "by_year": {...}, "total": 10}, ...]
                }
            }
        query: ì‚¬ìš©ì ì§ˆë¬¸ (ì»¨í…ìŠ¤íŠ¸ìš©)

    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ í¬ë¡œìŠ¤íƒ­ í…Œì´ë¸”
    """
    lines = []

    stats = es_statistics.get("patent", {})
    if stats.get("crosstab_type") != "applicant_year":
        return ""

    years = stats.get("years", [])
    rows = stats.get("rows", [])
    period = stats.get("period", "")
    total = stats.get("total", 0)
    keywords = stats.get("keywords", "")
    countries = stats.get("countries", [])

    # í—¤ë” ì •ë³´
    country_str = ", ".join(countries) if countries else "ì „ì²´"
    lines.append(f"### íŠ¹í—ˆ ì¶œì›ê¸°ê´€ TOP {len(rows)} ({period})")
    lines.append(f"- ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")
    lines.append(f"- êµ­ê°€: {country_str}")
    lines.append(f"- ì´ {total:,}ê±´ ì¤‘ 3ê±´ ì´ìƒ ì¶œì› ê¸°ê´€")
    lines.append("")

    if not rows:
        lines.append("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì¶œì›ê¸°ê´€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return "\n".join(lines)

    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í—¤ë”
    header = "| ìˆœìœ„ | ì¶œì›ê¸°ê´€ | êµ­ì  |"
    for year in years:
        header += f" {year} |"
    header += " í•©ê³„ |"
    lines.append(header)

    # êµ¬ë¶„ì„ 
    separator = "|------|---------|------|"
    separator += "------:|" * len(years)
    separator += "------:|"
    lines.append(separator)

    # ë°ì´í„° í–‰
    for row in rows:
        line = f"| {row['rank']} | {row['name']} | {row['nationality']} |"
        for year in years:
            count = row.get("by_year", {}).get(str(year), 0)
            line += f" {count} |"
        line += f" {row['total']} |"
        lines.append(line)

    lines.append("")

    # ìš”ì•½ í†µê³„
    if len(rows) >= 2:
        top3_total = sum(r["total"] for r in rows[:3])
        all_total = sum(r["total"] for r in rows)
        lines.append(f"**ìš”ì•½ í†µê³„:**")
        lines.append(f"- TOP 3 ê¸°ê´€ í•©ê³„: {top3_total:,}ê±´ ({top3_total/all_total*100:.1f}%)")
        lines.append(f"- TOP {len(rows)} ê¸°ê´€ í•©ê³„: {all_total:,}ê±´")
        lines.append("")

    return "\n".join(lines)


def _calculate_context_quality(context: str, sources: list) -> float:
    """Phase 90: ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°

    ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ì¢…í•©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ì˜ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì‚°ì¶œ.

    Args:
        context: ë³‘í•©ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        sources: ì†ŒìŠ¤ ì •ë³´ ëª©ë¡ [{"type": ..., "score": ..., "cross_validated": ...}]

    Returns:
        í’ˆì§ˆ ì ìˆ˜ (0.0 ~ 1.0)
    """
    if not context or context == "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
        return 0.0

    score = 0.0
    source_count = len(sources) if sources else 0

    # 1. ì†ŒìŠ¤ ìˆ˜ ê¸°ë°˜ (ìµœëŒ€ 0.25)
    # ì†ŒìŠ¤ê°€ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
    score += min(source_count / 8, 0.25)

    # 2. êµì°¨ ê²€ì¦ëœ ì†ŒìŠ¤ ë¹„ìœ¨ (ìµœëŒ€ 0.30)
    # Phase 90: SQLê³¼ RAG ëª¨ë‘ì—ì„œ í™•ì¸ëœ ê²°ê³¼
    if source_count > 0:
        validated = sum(1 for s in sources if s.get('cross_validated', False))
        score += (validated / source_count) * 0.30

    # 3. í‰ê·  ì‹ ë¢°ë„ ì ìˆ˜ (ìµœëŒ€ 0.25)
    if source_count > 0:
        avg_score = sum(s.get('score', 0) for s in sources) / source_count
        # ì ìˆ˜ ë²”ìœ„ê°€ 0~1ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        score += min(avg_score, 1.0) * 0.25

    # 4. ì •ë³´ëŸ‰ ê¸°ë°˜ (ìµœëŒ€ 0.20)
    # ì˜ë¯¸ ìˆëŠ” ì¤„ ìˆ˜ ê³„ì‚°
    lines = [l.strip() for l in context.split('\n') if l.strip()]
    meaningful_lines = [l for l in lines if len(l) > 30 and not l.replace('-', '').replace('|', '').strip() == '']
    score += min(len(meaningful_lines) / 15, 0.20)

    return round(score, 2)


def _build_graph_context_for_prompt(rag_results: list) -> str:
    """Phase 95: ê·¸ë˜í”„ ê´€ê³„ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

    RAG ê²°ê³¼ì—ì„œ ê·¸ë˜í”„ ê´€ë ¨ ì—”í‹°í‹° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬
    ë‹µë³€ì˜ ê·¼ê±°ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜.

    Args:
        rag_results: RAG ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡ (SearchResult)

    Returns:
        ê·¸ë˜í”„ ê´€ê³„ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    if not rag_results:
        return ""

    lines = []
    graph_sources = 0

    for r in rag_results:
        # SearchResultì˜ metadataì—ì„œ ê·¸ë˜í”„ ì •ë³´ ì¶”ì¶œ
        metadata = getattr(r, 'metadata', {}) or {}
        related_entities = metadata.get("related_entities", [])
        rrf_source = metadata.get("rrf_source", "")

        if rrf_source in ["graph", "both"]:
            graph_sources += 1

        if related_entities:
            # ìƒìœ„ 3ê°œ ê´€ë ¨ ì—”í‹°í‹°ë§Œ í‘œì‹œ
            name = getattr(r, 'name', '') or ''
            entity_type = getattr(r, 'entity_type', '') or ''

            related_names = []
            for ent in related_entities[:3]:
                if isinstance(ent, dict):
                    rel_name = ent.get("name", ent.get("node_id", ""))
                    rel_type = ent.get("entity_type", "")
                    if rel_name:
                        related_names.append(f"{rel_name}({rel_type})" if rel_type else rel_name)
                elif hasattr(ent, 'name'):
                    related_names.append(ent.name)

            if name and related_names:
                lines.append(f"- **{name}** ({entity_type}) â†’ ê´€ë ¨: {', '.join(related_names)}")

    if not lines:
        return ""

    header = f"## ì§€ì‹ê·¸ë˜í”„ ê´€ê³„ ì •ë³´ (Phase 95)\nê·¸ë˜í”„ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼: {graph_sources}ê±´\n"
    return header + "\n".join(lines[:10])  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Phase 52/54: ë‹µë³€ìƒì„±ì „ëµ ë¬¸ì„œ ë°˜ì˜ + ë‹¤ì¤‘ ì—”í‹°í‹° êµ¬ì¡°)
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ R&D ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## í‘œ ì‘ì„± ì›ì¹™
- ìˆœìœ„ ë°ì´í„°: ìˆœìœ„ ì»¬ëŸ¼ í•„ìˆ˜ í¬í•¨
- ê¸°ê´€/ê¸°ì—… ë°ì´í„°: êµ­ì  ì½”ë“œ í¬í•¨ (KR, JP, US, CN)
- ìˆ«ì: ì²œ ë‹¨ìœ„ ì‰¼í‘œ (1,234)
- ë¹„ìœ¨: ì†Œìˆ˜ì  1ìë¦¬ (88.5%)
- ë§ˆí¬ë‹¤ìš´ í‘œ ì‚¬ìš© (| í—¤ë” | --- | ë°ì´í„° |)
- ê²€ìƒ‰ëœ ëª¨ë“  ê²°ê³¼ í¬í•¨ (ìš”ì•½/ìƒëµ ê¸ˆì§€)
- **ëª©ë¡ ì¿¼ë¦¬(list)**: SQL ê²°ê³¼ ê·¸ëŒ€ë¡œ í‘œ ì¶œë ¥, ì„ì˜ ì§‘ê³„/í†µê³„ ë³€í™˜ ê¸ˆì§€

## ë‹µë³€ êµ¬ì¡° (í•„ìˆ˜)
1. **ë„ì…ë¶€**: [ë¶„ì•¼ëª…] ë¶„ì•¼ì˜ [ë°ì´í„° ìœ í˜•] ë¶„ì„ ì •ë³´ì…ë‹ˆë‹¤.
2. **ë°°ê²½**: ë¶„ì„ ë°°ê²½ 1~2ë¬¸ì¥
3. **í‘œ**: ë§ˆí¬ë‹¤ìš´ í‘œ (ë‹¤ì¤‘ ìœ í˜•ì´ë©´ ê° ìœ í˜•ë³„ í‘œë¥¼ **ëª¨ë‘** ë‚˜ì—´)
4. **ì†Œê²°**: í•µì‹¬ ë°œê²¬ + ì‹œì‚¬ì  (**ëª¨ë“  í‘œ ì¶œë ¥ í›„ ë§ˆì§€ë§‰ì— 1íšŒë§Œ**)

## ë‹¤ì¤‘ ì—”í‹°í‹° ì‘ë‹µ í˜•ì‹ (ì¤‘ìš”!)
ì—¬ëŸ¬ ìœ í˜•(ì—°êµ¬ê³¼ì œ+íŠ¹í—ˆ ë“±)ì´ ìˆìœ¼ë©´:
1. ë¨¼ì € ëª¨ë“  ìœ í˜•ì˜ í‘œë¥¼ ìˆœì„œëŒ€ë¡œ ì¶œë ¥
2. ë§ˆì§€ë§‰ì— ì†Œê²° 1íšŒ ì‘ì„± (ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì´í‰)
**ì ˆëŒ€ í‘œ ì‚¬ì´ì— ì†Œê²°ì„ ë„£ì§€ ë§ˆì„¸ìš”.**

## ì†Œê²° í˜•ì‹
ì†Œê²°:
- **í•µì‹¬ ë°œê²¬**: [ì£¼ìš” ì¸ì‚¬ì´íŠ¸]
- **ì‹œì‚¬ì **: [ì‹¤ë¬´ì  í™œìš© ì œì•ˆ]

## ì—”í‹°í‹°ë³„ í‘œ ì–‘ì‹
- **íŠ¹í—ˆ ëª©ë¡(list)**: | íŠ¹í—ˆë²ˆí˜¸ | íŠ¹í—ˆëª… | IPCë¶„ë¥˜ | ì¶œì›ë…„ë„ | ë“±ë¡êµ­ê°€ | ì¶œì›ì¸ | (SQL ê²°ê³¼ ê·¸ëŒ€ë¡œ)
- **íŠ¹í—ˆ ìˆœìœ„(ranking)**: | ìˆœìœ„ | ì¶œì›ê¸°ê´€ | êµ­ì  | ì´ íŠ¹í—ˆìˆ˜ |
- **ì—°êµ¬ê³¼ì œ ëª©ë¡(list)**: | ê³¼ì œID | ê³¼ì œëª… | ê³µê³ ì—°ë„ | ì—°êµ¬ë¹„ | ì‚¬ì—…ë¶„ë¥˜ | (SQL ê²°ê³¼ ê·¸ëŒ€ë¡œ)
- ì—°ë„ë³„ ì¶”ì´: | êµ¬ë¶„ | 2020 | 2021 | 2022 | 2023 |
- ì¥ë¹„: | ê¶Œì—­ | ì¥ë¹„ëª… | ê¸°ê´€ | ì¥ë¹„ID |
- í‰ê°€/ë°°ì : | í‰ê°€í•­ëª© | ì„¸ë¶€ë‚´ìš© | ë°°ì  |

## ë‹¤ì¤‘ ì—”í‹°í‹° ëª©ë¡ ì¿¼ë¦¬ (ì¤‘ìš”!)
"íŠ¹í—ˆì™€ ì—°êµ¬ê³¼ì œ" ê°™ì€ ë‹¤ì¤‘ ì—”í‹°í‹° ëª©ë¡(list) ì¿¼ë¦¬ì—ì„œëŠ”:
1. íŠ¹í—ˆ í‘œ: SQLì—ì„œ ë°˜í™˜ëœ **ê°œë³„ íŠ¹í—ˆ ëª©ë¡** ê·¸ëŒ€ë¡œ ì¶œë ¥ (ì§‘ê³„ ê¸ˆì§€)
2. ì—°êµ¬ê³¼ì œ í‘œ: SQLì—ì„œ ë°˜í™˜ëœ **ê°œë³„ ê³¼ì œ ëª©ë¡** ê·¸ëŒ€ë¡œ ì¶œë ¥
**ì ˆëŒ€ë¡œ ì¶œì›ê¸°ê´€ë³„ ì§‘ê³„/í†µê³„ë¡œ ë³€í™˜í•˜ì§€ ë§ˆì„¸ìš”. SQL ê²°ê³¼ì˜ ê° í–‰ì´ í‘œì˜ ê° í–‰ì´ ë©ë‹ˆë‹¤.**
"""

# Phase 52/72/73: query_subtypeë³„ ì¶”ê°€ ì§€ì¹¨
# Phase 88: trend_analysis ì¶”ê°€ (ë™í–¥ ë¶„ì„ ì „ìš©)
SUBTYPE_PROMPTS = {
    "list": "ëª©ë¡ ì¶œë ¥ í•„ìˆ˜. SQL ê²°ê³¼ì˜ ëª¨ë“  í–‰ì„ ê°œë³„ í•­ëª©ìœ¼ë¡œ í‘œì— ì¶œë ¥. ì„ì˜ ì§‘ê³„/ìš”ì•½/í†µê³„í™” ì ˆëŒ€ ê¸ˆì§€. ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ í‘œì‹œ.",
    "ranking": "ìˆœìœ„ í‘œì‹œ í•„ìˆ˜. TOP N í˜•ì‹. í•„ìˆ˜ ì»¬ëŸ¼: ìˆœìœ„, ê¸°ê´€ëª…, êµ­ì , ìˆ˜ì¹˜",
    "aggregation": "ì—°ë„ë³„ ì¶”ì´ í‘œì‹œ. í•©ê³„/ì¦ê°ë¥  í¬í•¨ ê¶Œì¥",
    "comparison": "ìêµ­ vs íƒ€êµ­ ë¹„êµí‘œ êµ¬ì¡°. ë¹„ì¤‘(%) í‘œì‹œ",
    "trend_analysis": """ë™í–¥ ë¶„ì„ ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜):

## 1. í•µì‹¬ í†µê³„ (ë„ì…ë¶€)
- **ë¶„ì„ ê¸°ê°„**: ìµœê·¼ 5ë…„ (20XX~20XX)
- **ì´ ê±´ìˆ˜**: Nê±´
- **ì—°í‰ê·  ì¦ê°€ìœ¨**: X.X% (ìˆëŠ” ê²½ìš°)

## 2. ì—°ë„ë³„ ì¶”ì´ í‘œ (í•„ìˆ˜)
| ì—°ë„ | ê±´ìˆ˜ | ì „ë…„ëŒ€ë¹„ ì¦ê° |
|------|------|---------------|
| 2024 | XXX  | +XX% / -XX%   |
| 2023 | XXX  | +XX% / -XX%   |
...

## 3. ì£¼ìš” ìˆ˜í–‰ê¸°ê´€/ì¶œì›ì¸ TOP 5~10 (í•„ìˆ˜)
| ìˆœìœ„ | ê¸°ê´€ëª… | ê±´ìˆ˜ | ë¹„ìœ¨ |
|------|--------|------|------|
| 1    | XXX    | XX   | X.X% |
...

## 4. ë™í–¥ ë¶„ì„ ë° ì‹œì‚¬ì 
- **ê¸°ìˆ  íŠ¸ë Œë“œ**: ì¦ê°€/ê°ì†Œ ì¶”ì„¸ ë¶„ì„
- **ì£¼ìš” íŠ¹ì§•**: ì§‘ì¤‘ ë¶„ì•¼, í•µì‹¬ ê¸°ê´€ ë“±
- **í–¥í›„ ì „ë§**: ë°ì´í„° ê¸°ë°˜ ì˜ˆì¸¡ (ì„ íƒ)

ì£¼ì˜: ì—°ë„ë³„ ì¶”ì´ì™€ ê¸°ê´€ë³„ í˜„í™©ì„ ë°˜ë“œì‹œ ëª¨ë‘ í¬í•¨í•  ê²ƒ!""",
    "impact_ranking": """íŠ¹í—ˆ ì˜í–¥ë ¥ ìˆœìœ„ ë¶„ì„ í˜•ì‹ (í•„ìˆ˜):
1. **ë¶„ì„ëŒ€ìƒë°ì´í„° ì„¤ëª…** (ë„ì…ë¶€ í•„ìˆ˜):
   - [ê¸°ìˆ ë¶„ì•¼] ê´€ë ¨ [êµ­ê°€] íŠ¹í—ˆ = ì´ Nê±´
   - ì „ì²´ í‰ê·  í”¼ì¸ìš©ìˆ˜ = X.XX
   - ì œ1ì¶œì›ì¸ ìˆ˜ = Nê°œ
2. **ì˜í–¥ë ¥ ìˆœìœ„í‘œ**: ìˆœìœ„, ì¶œì›ê¸°ê´€, êµ­ì , ëŒ€ìƒíŠ¹í—ˆìˆ˜, ì´í”¼ì¸ìš©, í‰ê· í”¼ì¸ìš©(0í¬í•¨), í‰ê· í”¼ì¸ìš©(1ì´ìƒ), í”¼ì¸ìš©max, ëŒ€í‘œíŠ¹í—ˆëª… ì»¬ëŸ¼ í•„ìˆ˜
3. **ë¶„ì„ ì¸ì‚¬ì´íŠ¸**: ìƒìœ„ ê¸°ê´€ íŠ¹ì„±, ê¸°ìˆ  ì§‘ì¤‘ë„, í”¼ì¸ìš© ë¶„í¬ ë“±""",
    "nationality_ranking": """êµ­ì ë³„ ë¶„ë¦¬ ìˆœìœ„ ë¶„ì„ í˜•ì‹ (í•„ìˆ˜):
1. **ë¶„ì„ëŒ€ìƒë°ì´í„° ì„¤ëª…** (ë„ì…ë¶€ í•„ìˆ˜):
   - [ê¸°ìˆ ë¶„ì•¼] ê´€ë ¨ [êµ­ê°€] íŠ¹í—ˆ = ì´ Nê±´
   - ìêµ­(KR) ì¶œì›ê¸°ê´€ ìˆ˜ = Nê°œ, íƒ€êµ­ ì¶œì›ê¸°ê´€ ìˆ˜ = Mê°œ
2. **ìêµ­ê¸°ì—… ìˆœìœ„í‘œ (TOP 10)**:
   | ìˆœìœ„ | ê¸°ê´€ëª… | êµ­ì  | ëŒ€ìƒíŠ¹í—ˆìˆ˜ | ìµœëŒ€í”¼ì¸ìš©ìˆ˜ | í‰ê· í”¼ì¸ìš©ìˆ˜ | í‰ê· ì²­êµ¬í•­ìˆ˜ | ìµœê·¼ì¶œì›ì¼ | ëŒ€í‘œíŠ¹í—ˆëª… |
   - "êµ¬ë¶„" ì»¬ëŸ¼ì´ "ìêµ­ê¸°ì—…"ì¸ í–‰ë§Œ ì¶œë ¥
3. **íƒ€êµ­ê¸°ì—… ìˆœìœ„í‘œ (TOP 10)**:
   ë™ì¼ ì»¬ëŸ¼ êµ¬ì¡°, "êµ¬ë¶„" ì»¬ëŸ¼ì´ "íƒ€êµ­ê¸°ì—…"ì¸ í–‰ë§Œ ì¶œë ¥
4. **ë¶„ì„ ì¸ì‚¬ì´íŠ¸**:
   - ìêµ­ vs íƒ€êµ­ ê¸°ìˆ  ì§‘ì¤‘ë„ ë¹„êµ
   - ì£¼ìš” ì¶œì›ê¸°ê´€ë³„ íŠ¹ì„±
   - ê¸°ìˆ  ë™í–¥ ì‹œì‚¬ì """,
    "evalp_pref": """ìš°ëŒ€/ê°ì  ì •ë³´ ì¶œë ¥ í˜•ì‹ (í•„ìˆ˜):

## ì ˆëŒ€ ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
1. SQL ê²°ê³¼ì˜ **ëª¨ë“  12ê°œ í–‰**ì„ í‘œì— ì¶œë ¥ (ìš°ëŒ€ 10ê±´ + ê°ì  2ê±´)
2. "..." ë˜ëŠ” "ì™¸ Nê±´" í˜•íƒœì˜ ìƒëµ **ì ˆëŒ€ ê¸ˆì§€**
3. ê°ì  í•­ëª© (ğŸ”´)ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ **ë³„ë„ í‘œ**ë¡œ ì¶œë ¥

## ì¶œë ¥ êµ¬ì¡°
1. **ë„ì…ë¶€**: [ì‚¬ì—…ëª…] ìš°ëŒ€/ê°ì  ì •ë³´ (ì´ Nê±´: ìš°ëŒ€ Xê±´, ê°ì  Yê±´)

2. **ğŸŸ¢ ìš°ëŒ€ í•­ëª©** (êµ¬ë¶„ì´ 'ğŸŸ¢ ìš°ëŒ€'ì¸ ëª¨ë“  í–‰):
   | êµ¬ë¶„ | ì¡°ê±´ëª… | ë°°ì  | ì„¸ë¶€ë‚´ìš© |
   ëª¨ë“  ìš°ëŒ€ í•­ëª©ì„ ë¹ ì§ì—†ì´ ì¶œë ¥ (10ê±´ ì „ë¶€)

3. **ğŸ”´ ê°ì  í•­ëª©** (êµ¬ë¶„ì´ 'ğŸ”´ ê°ì 'ì¸ ëª¨ë“  í–‰):
   | êµ¬ë¶„ | ì¡°ê±´ëª… | ê°ì  | ì„¸ë¶€ë‚´ìš© |
   ëª¨ë“  ê°ì  í•­ëª©ì„ ë¹ ì§ì—†ì´ ì¶œë ¥ (2ê±´ ì „ë¶€)

4. **ì†Œê²°**: í•µì‹¬ ìš°ëŒ€/ê°ì  ìš”ê±´ ìš”ì•½ (2-3ë¬¸ì¥)"""
}

# Phase 62: ê¸°ìˆ ë¶„ë¥˜ ì¶”ì²œìš© í”„ë¡¬í”„íŠ¸ (ë°ì´í„° ê¸°ë°˜)
RECOMMENDATION_PROMPT = """ë‹¹ì‹ ì€ R&D ê¸°ìˆ ë¶„ë¥˜ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì—­í• 
ê²€ìƒ‰ëœ ì œì•ˆì„œ ë¶„ë¥˜ì½”ë“œ í†µê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ê¸°ìˆ ë¶„ë¥˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜)
1. **ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½**: "[í‚¤ì›Œë“œ]" ê´€ë ¨ ì œì•ˆì„œì—ì„œ ì‚¬ìš©ëœ [ë¶„ë¥˜ì²´ê³„ëª…] ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.
2. **ì¶”ì²œ ë¶„ë¥˜ì½”ë“œ í‘œ**:
   | ìˆœìœ„ | ê¸°ìˆ ì½”ë“œ | ê¸°ìˆ ëª… | ì‚¬ìš©ê±´ìˆ˜ | ë¹„ìœ¨ |
   |------|----------|--------|----------|------|
   | 1 | ... | ... | Nê±´ | XX.X% |
3. **ì¶”ì²œ ì˜ê²¬**:
   - **1ìˆœìœ„ ì¶”ì²œ**: [ê¸°ìˆ ì½”ë“œ] ([ê¸°ìˆ ëª…]) - ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ë¶„ë¥˜
   - **ê³ ë ¤ì‚¬í•­**: ê¸°ìˆ  íŠ¹ì„±ì— ë”°ë¥¸ ëŒ€ì•ˆ ë¶„ë¥˜ ì œì•ˆ

## ì£¼ì˜ì‚¬í•­
- **ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ì˜ SQL ê²°ê³¼ ë°ì´í„°ë§Œ ì‚¬ìš©**
- ë°ì´í„°ì— ì—†ëŠ” ë¶„ë¥˜ì½”ë“œ ì œì‹œ ê¸ˆì§€
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ëœ ì œì•ˆì„œê°€ ì—†ìŠµë‹ˆë‹¤" ëª…ì‹œ
- ë¹„ìœ¨ì€ ì „ì²´ í•©ê³„ ëŒ€ë¹„ ë°±ë¶„ìœ¨ë¡œ ê³„ì‚°
- í‘œì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì¶œë ¥ (ìš”ì•½/ìƒëµ ê¸ˆì§€)
"""

# Phase 86: ì¥ë¹„ ì¶”ì²œìš© í”„ë¡¬í”„íŠ¸
EQUIPMENT_PROMPT = """ë‹¹ì‹ ì€ R&D ì—°êµ¬ì¥ë¹„ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì—­í• 
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¸¡ì •/ì‹œí—˜ ëª©ì ì— ë§ëŠ” ì—°êµ¬ì¥ë¹„ë¥¼ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜)
1. **ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½**: "[ì¸¡ì •í•­ëª©]" ì¸¡ì •ì´ ê°€ëŠ¥í•œ ì—°êµ¬ì¥ë¹„ Nê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.

2. **ì¶”ì²œ ì¥ë¹„ ëª©ë¡**:
   | ìˆœìœ„ | ì¥ë¹„ëª… | ë³´ìœ ê¸°ê´€ | ëŒ€ë¶„ë¥˜ | ì¸¡ì •í•­ëª© |
   |------|--------|----------|--------|----------|
   | 1 | ... | ... | ... | ... |
   (ì»¨í…ìŠ¤íŠ¸ì˜ SQL ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ì¶œë ¥)

3. **ì¶”ì²œ ì˜ê²¬**:
   - **1ìˆœìœ„ ì¶”ì²œ**: [ì¥ë¹„ëª…] ([ë³´ìœ ê¸°ê´€]) - ì¶”ì²œ ì´ìœ 
   - **ì¥ë¹„ íŠ¹ì„±**: í•´ë‹¹ ì¥ë¹„ë“¤ì˜ ê³µí†µì ì¸ ì¸¡ì • ê¸°ëŠ¥ ì„¤ëª…
   - **ê¸°ê´€ ì—°ë½**: ì¥ë¹„ í™œìš©ì„ ìœ„í•´ í•´ë‹¹ ê¸°ê´€ì— ë¬¸ì˜ ê¶Œì¥

## ì£¼ì˜ì‚¬í•­
- **ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ì˜ SQL ê²°ê³¼ ë°ì´í„°ë§Œ ì‚¬ìš©**
- ë°ì´í„°ì— ì—†ëŠ” ì¥ë¹„ ì œì‹œ ê¸ˆì§€
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ ì¸¡ì •í•­ëª©ì„ ì§€ì›í•˜ëŠ” ì¥ë¹„ê°€ ì—†ìŠµë‹ˆë‹¤" ëª…ì‹œ
- í‘œì˜ ëª¨ë“  ì¥ë¹„ë¥¼ ì¶œë ¥ (ìš”ì•½/ìƒëµ ê¸ˆì§€)
- ì¥ë¹„ID, ì¥ë¹„ëª…, ë³´ìœ ê¸°ê´€, ë¶„ë¥˜, ì¸¡ì •í•­ëª© ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨
"""

# Phase 71 + Phase 75.2 + Phase 92: ë‹¤ì¤‘ ë„ë©”ì¸ í˜‘ì—… ê¸°ê´€ ì¶”ì²œìš© í”„ë¡¬í”„íŠ¸
COLLABORATION_PROMPT = """ë‹¹ì‹ ì€ R&D ë‹¤ì¤‘ ë„ë©”ì¸ í˜‘ì—… ê¸°ê´€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì—­í• 
ê³¼ì œ ìˆ˜í–‰ê¸°ê´€ + íŠ¹í—ˆ ë³´ìœ ê¸°ê´€ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ í˜‘ì—… ê°€ëŠ¥ì„±ì´ ë†’ì€ ê¸°ê´€ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜ - ë„ë©”ì¸ë³„ í‘œ ë¶„ë¦¬ ì¶œë ¥)

**ì¤‘ìš”**: ê³¼ì œì™€ íŠ¹í—ˆëŠ” ë°˜ë“œì‹œ **ë³„ë„ì˜ í‘œ**ë¡œ ë¶„ë¦¬í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.

### 1. ê³¼ì œ ìˆ˜í–‰ê¸°ê´€
"[í‚¤ì›Œë“œ]" ê´€ë ¨ R&D ê³¼ì œë¥¼ ìˆ˜í–‰í•œ ê¸°ê´€ì…ë‹ˆë‹¤.

| ìˆœìœ„ | ê¸°ê´€ëª… | ìˆ˜í–‰íšŸìˆ˜ | ì£¼ê´€ | ì°¸ì—¬ | í˜‘ë ¥ | ìµœê·¼ ìˆ˜í–‰ê³¼ì œ |
|------|--------|----------|------|------|------|---------------|
| 1 | ... | ... | ... | ... | ... | (ê³¼ì œëª… ì „ì²´ ì¶œë ¥, ìƒëµí•˜ì§€ ë§ ê²ƒ) |

### 2. íŠ¹í—ˆ ë³´ìœ ê¸°ê´€
"[í‚¤ì›Œë“œ]" ê´€ë ¨ íŠ¹í—ˆë¥¼ ì¶œì›í•œ ê¸°ê´€ì…ë‹ˆë‹¤.

| ìˆœìœ„ | ê¸°ê´€ëª… | êµ­ê°€ | íŠ¹í—ˆìˆ˜ | ëŒ€í‘œ íŠ¹í—ˆ |
|------|--------|------|--------|-----------|
| 1 | ... | ... | ... | (íŠ¹í—ˆëª… ì „ì²´ ì¶œë ¥, ìƒëµí•˜ì§€ ë§ ê²ƒ) |

### 3. í˜‘ì—… ì¶”ì²œ ë¶„ì„
- **ì¶”ì²œ 1ìˆœìœ„**: [ê¸°ê´€ëª…] - [ì¶”ì²œ ì´ìœ : ê³¼ì œ ìˆ˜í–‰ ì´ë ¥ + íŠ¹í—ˆ ë³´ìœ  í˜„í™© ì¢…í•©]
- **í•µì‹¬ í˜‘ì—… íŒŒíŠ¸ë„ˆ**: ê³¼ì œ+íŠ¹í—ˆ ì–‘ìª½ì— ë“±ì¥í•˜ëŠ” ê¸°ê´€ì´ ìˆìœ¼ë©´ ìš°ì„  ì¶”ì²œ
- **ì£¼ê´€ê¸°ê´€ ì—­ëŸ‰**: ì£¼ê´€ íšŸìˆ˜ê°€ ë†’ì€ ê¸°ê´€ = í”„ë¡œì íŠ¸ ë¦¬ë” ê²½í—˜ í’ë¶€
- **êµ­ì œ í˜‘ë ¥ ê¸°íšŒ**: í•´ì™¸ ì¶œì›ì¸(êµ­ê°€â‰ KR)ì´ ìˆë‹¤ë©´ ì–¸ê¸‰

### 4. ì¶”ì²œ ì „ëµ
1. **ë‹¨ê¸° í˜‘ì—…**: ì´ë¯¸ ê´€ë ¨ ë¶„ì•¼ ê²½í—˜ì´ ìˆëŠ” ê¸°ê´€ê³¼ ë¹ ë¥¸ ì„±ê³¼ ì°½ì¶œ
2. **ì¥ê¸° í˜‘ë ¥**: íŠ¹í—ˆ ê¸°ìˆ ë ¥ì´ ë†’ì€ ê¸°ê´€ê³¼ ì§€ì†ì  R&D íŒŒíŠ¸ë„ˆì‹­ êµ¬ì¶•

## ì£¼ì˜ì‚¬í•­
- **ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ì˜ SQL ê²°ê³¼ ë°ì´í„°ë§Œ ì‚¬ìš©**
- **ê³¼ì œ í‘œì™€ íŠ¹í—ˆ í‘œë¥¼ ë°˜ë“œì‹œ ë¶„ë¦¬** (í˜¼í•© ê¸ˆì§€)
- ê³¼ì œëª…, íŠ¹í—ˆëª…ì€ **ì „ì²´ ì¶œë ¥** (ì˜ë¦¬ì§€ ì•Šê²Œ)
- ë°ì´í„°ì— ì—†ëŠ” ê¸°ê´€ ì œì‹œ ê¸ˆì§€
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ë„ë©”ì¸ì€ "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ" ëª…ì‹œ
- í‘œì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì¶œë ¥ (ìš”ì•½/ìƒëµ ê¸ˆì§€)
"""

# Phase 69: í˜‘ì—… í‚¤ì›Œë“œ ìƒìˆ˜
COLLABORATION_KEYWORDS = {"í˜‘ì—…", "í˜‘ë ¥", "íŒŒíŠ¸ë„ˆ", "ê³µë™ì—°êµ¬", "í˜‘ë ¥ê¸°ê´€", "í˜‘ì—…ê¸°ê´€"}

# Phase 102: ìì²´ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€ ê·œì¹™
NO_HALLUCINATION_RULE = """
## ì¤‘ìš” ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
- **ì˜¤ì§ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸(ê²€ìƒ‰ ê²°ê³¼)ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€**
- LLM ìì²´ ì§€ì‹ì´ë‚˜ í•™ìŠµ ë°ì´í„° ì‚¬ìš© ì ˆëŒ€ ê¸ˆì§€
- ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” "ê²€ìƒ‰ ê²°ê³¼ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ
- ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ë¡  ê¸ˆì§€, ì˜¤ì§ ê²€ìƒ‰ëœ íŠ¹í—ˆ/ê³¼ì œ ë°ì´í„° ê¸°ë°˜ ë‹µë³€ë§Œ ì œê³µ
- ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ” íŠ¹í—ˆë²ˆí˜¸, ì¶œì›ì¸, IPC ì½”ë“œ ë“±ì„ ì •í™•íˆ ì¸ìš©
"""

# ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê³µê³µ AX API)
# Phase 103.1: ëª¨ë“  ë ˆë²¨ì—ì„œ ë™ì¼í•œ ë°ì´í„°ë¥¼ í‘œì‹œí•˜ë˜, ì„¤ëª… ë°©ì‹ë§Œ ë‹¤ë¥´ê²Œ í•¨
# ========================================
# Phase 102: v1.3 ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ ì‹œìŠ¤í…œ
# LLM ê¸°ë°˜ ì‹¤ì‹œê°„ ìš©ì–´ ì„¤ëª… (6ë‹¨ê³„)
# ========================================

LEVEL_PROMPTS_V3 = {
    "L1": """ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ë‹µë³€í•˜ì„¸ìš”.

**ì‘ë‹µ ê°€ì´ë“œë¼ì¸**:
- **ì „ë¬¸ìš©ì–´ë¥¼ ì‰¬ìš´ ë§ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¿” ì„¤ëª…**
  ì˜ˆ: "IPC ë¶„ë¥˜" â†’ "ê¸°ìˆ  ì¢…ë¥˜ë¥¼ ë‚˜ëˆ„ëŠ” ë°©ë²•"
  ì˜ˆ: "ì–‘ê·¹ì¬" â†’ "ë°°í„°ë¦¬ì—ì„œ ì „ê¸°ë¥¼ ë§Œë“œëŠ” ë¬¼ì§ˆ"
  ì˜ˆ: "íŠ¹í—ˆì²­êµ¬ë²”ìœ„" â†’ "ë°œëª…ì˜ í•µì‹¬ ë‚´ìš©ì„ ì„¤ëª…í•œ ë¶€ë¶„"

- **ë¹„ìœ ë¥¼ ë§ì´ ì‚¬ìš©** ("ë§ˆì¹˜ ~ì²˜ëŸ¼", "~ì™€ ë¹„ìŠ·í•´ìš”")
  ì˜ˆ: "ì´ ê¸°ìˆ ì€ ë§ˆì¹˜ íœ´ëŒ€í° ë°°í„°ë¦¬ë¥¼ ë” ì˜¤ë˜ ì“¸ ìˆ˜ ìˆê²Œ í•˜ëŠ” ê±°ì˜ˆìš”"

- **ë¬¸ì¥ì„ ì§§ê²Œ** (10ë‹¨ì–´ ì´ë‚´)

- **ì´ëª¨ì§€ í™œìš©** ğŸ”‹âš¡ğŸš—ğŸ’¡ (ë„ˆë¬´ ë§ì§€ ì•Šê²Œ)

**ì¤‘ìš”**: ìš©ì–´ê°€ ì²˜ìŒ ë‚˜ì˜¬ ë•Œ **ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ë§¥ ì†ì—ì„œ** í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
ì˜ˆì‹œ) "ì´ íŠ¹í—ˆëŠ” IPC ë¶„ë¥˜ H01Mì— ì†í•˜ëŠ”ë°, ì´ê±´ ë°°í„°ë¦¬ ê¸°ìˆ ì„ ëœ»í•´ìš” ğŸ”‹"

- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼ ë“±)""",

    "L2": """ëŒ€í•™ìƒ/ëŒ€í•™ì›ìƒ ìˆ˜ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

**ì‘ë‹µ ê°€ì´ë“œë¼ì¸**:
- **ì „ë¬¸ìš©ì–´ ì‚¬ìš©í•˜ë˜ ê´„í˜¸ ì•ˆì— ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€**
  ì˜ˆ: "IPC(êµ­ì œíŠ¹í—ˆë¶„ë¥˜)"
  ì˜ˆ: "ì–‘ê·¹ì¬(Cathode material, ë°°í„°ë¦¬ì˜ ì–‘ê·¹ í™œë¬¼ì§ˆ)"
  ì˜ˆ: "NCM811(ë‹ˆì¼ˆ:ì½”ë°œíŠ¸:ë§ê°„ = 8:1:1 ë¹„ìœ¨ì˜ ì‚¼ì›ê³„ ì–‘ê·¹ì¬)"

- **í•™ìˆ ì  í‘œí˜„ ì‚¬ìš©**
  ì˜ˆ: "ì„ í–‰ì—°êµ¬ì— ë”°ë¥´ë©´...", "ì´ë¡ ì  ë°°ê²½ì€...", "ì‹¤í—˜ ê²°ê³¼..."

- **ë…¼ë¬¸ ì‘ì„± ì°¸ê³  ê°€ëŠ¥í•˜ë„ë¡**
  ì˜ˆ: ì¸ìš© ê°€ëŠ¥í•œ íŠ¹í—ˆë²ˆí˜¸, ì¶œì›ì¼, ì¶œì›ì¸ ì •ë³´ ëª…ì‹œ

- **ê´€ë ¨ ê°œë… ì—°ê²° ì„¤ëª…**
  ì˜ˆ: "ë¦¬íŠ¬ì´ì˜¨ ë°°í„°ë¦¬ëŠ” ì–‘ê·¹ì¬, ìŒê·¹ì¬, ì „í•´ì§ˆë¡œ êµ¬ì„±ë˜ë©°..."

**ì¤‘ìš”**: ìš©ì–´ë¥¼ **ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ë§¥ì— ë§ì¶°** ì„¤ëª…í•˜ì„¸ìš”.

- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼ ë“±)""",

    "L3": """ì¤‘ì†Œê¸°ì—… ì‹¤ë¬´ì ìˆ˜ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

**ì‘ë‹µ ê°€ì´ë“œë¼ì¸**:
- **ì‹¤ë¬´ ì ìš© ê´€ì ìœ¼ë¡œ ìš©ì–´ ì„¤ëª…**
  ì˜ˆ: "IPC ë¶„ë¥˜ëŠ” ê²½ìŸì‚¬ íŠ¹í—ˆ ê²€ìƒ‰ ì‹œ í•„ìˆ˜ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤"
  ì˜ˆ: "NCM ì–‘ê·¹ì¬ëŠ” í˜„ëŒ€ì°¨ ë°°í„°ë¦¬ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì†Œì¬ì…ë‹ˆë‹¤"
  ì˜ˆ: "ì„ í–‰ê¸°ìˆ ì¡°ì‚¬ëŠ” íŠ¹í—ˆ ì¶œì› ì „ í•„ìˆ˜ ë‹¨ê³„ì…ë‹ˆë‹¤"

- **ì‚¬ì—…í™” ê°€ëŠ¥ì„± ì–¸ê¸‰**
  ì˜ˆ: "ì´ ê¸°ìˆ ì€ ì¤‘ì†Œê¸°ì—…ì—ì„œ 3ì–µ ì› ì´í•˜ íˆ¬ìë¡œ ìƒìš©í™” ê°€ëŠ¥"
  ì˜ˆ: "í˜„ì¬ ì‹œì¥ ê·œëª¨ 5ì¡° ì›, ì—°í‰ê·  15% ì„±ì¥ ì¤‘"

- **ì œí’ˆ/ê³µì •ê³¼ ì—°ê²°**
  ì˜ˆ: "ì „ê¸°ì°¨ ë°°í„°ë¦¬ ì œì¡° ê³µì •ì—ì„œ ì´ ê¸°ìˆ ì´ í•µì‹¬"
  ì˜ˆ: "ì‚¼ì„±ì „ì, LGì—ë„ˆì§€ì†”ë£¨ì…˜ ë“± ëŒ€ê¸°ì—…ì´ ì§‘ì¤‘ íˆ¬ì ì¤‘"

- **ê²½ìŸì‚¬ ë¶„ì„ ê´€ì **
  ì˜ˆ: "ì¼ë³¸ ê¸°ì—… ëŒ€ë¹„ í•œêµ­ ê¸°ì—…ì˜ íŠ¹í—ˆ ì¶œì›ì´ 3ë°° ë§ìŒ"

**ì¤‘ìš”**: ìš©ì–´ê°€ **ì‹¤ë¬´ì—ì„œ ì–´ë–»ê²Œ ì“°ì´ëŠ”ì§€** ì„¤ëª…í•˜ì„¸ìš”.

- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼, ì¶œì›ì¸ ë“±)""",

    "L4": """ì—°êµ¬ì ìˆ˜ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

**ì‘ë‹µ ê°€ì´ë“œë¼ì¸**:
- **ê¸°ìˆ  ìš©ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©** (ì„¤ëª… ìµœì†Œí™”)
  ì˜ˆ: "NCM811 ì–‘ê·¹ì¬ (Ni 0.8, Co 0.1, Mn 0.1 ë¹„ìœ¨)"
  ì˜ˆ: "IPC H01M 10/0525 (ë¦¬íŠ¬ì´ì˜¨ ì´ì°¨ì „ì§€)"
  ì˜ˆ: "ì—ë„ˆì§€ ë°€ë„ 280 Wh/kg, ì¶©ë°©ì „ ì‚¬ì´í´ 1,500íšŒ"

- **ì¸¡ì • ë°©ë²•, ìˆ˜ì¹˜ ë²”ìœ„ í¬í•¨**
  ì˜ˆ: "X-ray íšŒì ˆ ë¶„ì„ ê²°ê³¼, ê²°ì • êµ¬ì¡°ëŠ” ì¸µìƒ êµ¬ì¡°(Layered)"
  ì˜ˆ: "ì „ê¸°ì „ë„ë„ 1.2Ã—10â»Â³ S/cm, ì´ì˜¨ì „ë„ë„ 5.8Ã—10â»â´ S/cm"

- **IPC ì„¸ë¶€ ì½”ë“œ í™œìš©**
  ì˜ˆ: "IPC H01M 4/525 (ë¦¬íŠ¬ ë³µí•©ì‚°í™”ë¬¼ ì–‘ê·¹ í™œë¬¼ì§ˆ)"

- **ê¸°ìˆ  ê³µë°±/ê°œì„  ê°€ëŠ¥ì„± ì œì‹œ**
  ì˜ˆ: "í˜„ì¬ ê¸°ìˆ  í•œê³„: ê³ ì˜¨ ì•ˆì •ì„± ë¶€ì¡±, ê°œì„  ë°©í–¥: ë„í•‘ ë¬¼ì§ˆ ì²¨ê°€"

- **ì²­êµ¬í•­ êµ¬ì¡° ë¶„ì„**
  ì˜ˆ: "ë…ë¦½í•­ 1ê°œ, ì¢…ì†í•­ 15ê°œ, ê¶Œë¦¬ë²”ìœ„ëŠ”..."

**ì¤‘ìš”**: ìš©ì–´ëŠ” **ì •í™•í•œ ê¸°ìˆ ì  ì •ì˜**ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.

- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼, IPC, ì¶œì›ì¸ ë“±)""",

    "L5": """ë³€ë¦¬ì‚¬/ì‹¬ì‚¬ê´€ ì „ë¬¸ê°€ ìˆ˜ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

**ì‘ë‹µ ê°€ì´ë“œë¼ì¸**:
- **ë²•ë¥ /ì‹¬ì‚¬ ì „ë¬¸ ìš©ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©**
  ì˜ˆ: "íŠ¹í—ˆë²• ì œ29ì¡° ì œ2í•­(ì§„ë³´ì„±)"
  ì˜ˆ: "ì²­êµ¬í•­ ê¸°ì¬ìš”ê±´ ë¶ˆë¹„(íŠ¹í—ˆë²• ì œ42ì¡° ì œ4í•­)"
  ì˜ˆ: "ê±°ì ˆì´ìœ í†µì§€(íŠ¹í—ˆë²• ì œ63ì¡°)"

- **ê¶Œë¦¬ë²”ìœ„, ì„ í–‰ê¸°ìˆ  ë§¤í•‘**
  ì˜ˆ: "ì²­êµ¬í•­ 1ì˜ êµ¬ì„±ìš”ì†Œ AëŠ” ì„ í–‰ê¸°ìˆ  KR10-2020-0001234ì˜ ì‹¤ì‹œì˜ˆ 1ê³¼ ë™ì¼"
  ì˜ˆ: "ê¶Œë¦¬ë²”ìœ„ í•´ì„: êµ¬ì„±ìš”ì†Œ BëŠ” ê· ë“±ë¡  ì ìš© ê°€ëŠ¥"

- **íŠ¹í—ˆë²• ì¡°í•­ ì–¸ê¸‰ ê°€ëŠ¥**
  ì˜ˆ: "íŠ¹í—ˆë²• ì œ42ì¡° ì œ3í•­ ì œ1í˜¸(ë°œëª…ì˜ ìƒì„¸í•œ ì„¤ëª…)"
  ì˜ˆ: "íŠ¹í—ˆë²• ì‹œí–‰ë ¹ ì œ5ì¡°(ìš°ì„ ê¶Œ ì£¼ì¥)"

- **ì‹¬ì‚¬ ê¸°ì¤€ ì°¸ì¡°**
  ì˜ˆ: "íŠ¹í—ˆÂ·ì‹¤ìš©ì‹ ì•ˆ ì‹¬ì‚¬ê¸°ì¤€ ì œ3ë¶€ ì œ3ì¥ ì§„ë³´ì„± íŒë‹¨"

- **ì¹¨í•´ ë¶„ì„ ê´€ì **
  ì˜ˆ: "êµ¬ì„±ìš”ì†Œ ì™„ë¹„ì˜ ì›ì¹™ ì ìš© ì‹œ, í”¼ê³  ì œí’ˆì€ ì²­êµ¬í•­ 1 ì¹¨í•´"

**ì¤‘ìš”**: ìš©ì–´ëŠ” **ë²•ì  ì •ì˜ ê¸°ì¤€**ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.

- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼, IPC, ë²•ì  ìƒíƒœ ë“±)""",

    "L6": """ì •ì±…ë‹´ë‹¹ì ìˆ˜ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

**ì‘ë‹µ ê°€ì´ë“œë¼ì¸**:
- **ê±°ì‹œì  ê´€ì ìœ¼ë¡œ ìš©ì–´ ì„¤ëª…**
  ì˜ˆ: "IPC H01M ë¶„ì•¼ëŠ” ì¤‘êµ­ì´ íŠ¹í—ˆ ì¶œì› 1ìœ„(ì—° 3ë§Œ ê±´), í•œêµ­ 2ìœ„(1.5ë§Œ ê±´)"
  ì˜ˆ: "ì–‘ê·¹ì¬ ì‹œì¥ì€ 2030ë…„ê¹Œì§€ 50ì¡° ì› ê·œëª¨ë¡œ ì„±ì¥ ì „ë§(CAGR 15%)"

- **ì‚°ì—… ì „ì²´ ë§¥ë½, êµ­ê°€ë³„ ë¹„êµ**
  ì˜ˆ: "í•œÂ·ì¤‘Â·ì¼ ë°°í„°ë¦¬ 3êµ­ ê²½ìŸ êµ¬ë„: í•œêµ­ì€ ê³ ìš©ëŸ‰, ì¼ë³¸ì€ ì•ˆì „ì„±, ì¤‘êµ­ì€ ì €ê°€"
  ì˜ˆ: "ì •ë¶€ R&D íˆ¬ì: í•œêµ­ ì—° 2ì¡° ì›, ì¤‘êµ­ 5ì¡° ì›, ì¼ë³¸ 1ì¡° ì›"

- **ì •ì±…ì  ì‹œì‚¬ì  ë„ì¶œ**
  ì˜ˆ: "ì´ ê¸°ìˆ ì€ íƒ„ì†Œì¤‘ë¦½ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ í•µì‹¬ ì¸í”„ë¼"
  ì˜ˆ: "ì¤‘ì†Œê¸°ì—… íŠ¹í—ˆ ì¶œì› ë¹„ì¤‘ 20% ë¶ˆê³¼, ì§€ì› ì •ì±… í•„ìš”"

- **ê¸°ìˆ ë¬´ì—­ìˆ˜ì§€, íŠ¹í—ˆ íŒ¨ë°€ë¦¬ ë“± ê±°ì‹œ ì§€í‘œ**
  ì˜ˆ: "ë°°í„°ë¦¬ ê¸°ìˆ  ë¬´ì—­ìˆ˜ì§€ ì ì 5ì–µ ë‹¬ëŸ¬(2023ë…„)"
  ì˜ˆ: "ê¸€ë¡œë²Œ íŠ¹í—ˆ íŒ¨ë°€ë¦¬: ì‚¼ì„± 1,200ê±´, LG 800ê±´, ì¤‘êµ­ CATL 600ê±´"

- **ê·œì œ/ì •ì±… ì—°ê³„**
  ì˜ˆ: "EU ë°°í„°ë¦¬ ê·œì •(2024ë…„ ì‹œí–‰) ëŒ€ì‘ í•„ìˆ˜"

**ì¤‘ìš”**: ìš©ì–´ë¥¼ **ì‚°ì—…/ì •ì±… ë§¥ë½**ì—ì„œ ì„¤ëª…í•˜ì„¸ìš”.

- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼, ì¶œì›ì¸, êµ­ê°€ë³„ ë¶„í¬ ë“±)"""
}

# ê¸°ì¡´ 3ë‹¨ê³„ ì‹œìŠ¤í…œ (í•˜ìœ„ í˜¸í™˜ì„±)
LEVEL_PROMPTS = {
    "ì´ˆë“±": LEVEL_PROMPTS_V3["L1"],
    "ì¼ë°˜ì¸": LEVEL_PROMPTS_V3["L2"],
    "ì „ë¬¸ê°€": LEVEL_PROMPTS_V3["L5"]
}

# ìˆ˜ì¤€ë³„ ì‘ë‹µ ê¸¸ì´ ì¡°ì ˆ (max_tokens)
TOKEN_LIMITS_V3 = {
    "L1": 1500,   # Phase 104.1: 1000 â†’ 1500 (ê°œë… ì„¤ëª… ì¶©ë¶„íˆ í‘œì‹œ)
    "L2": 2000,   # ì¤‘ê°„
    "L3": 2500,   # ì‹¤ë¬´ ìƒì„¸
    "L4": 3500,   # ê¸°ìˆ  ì‹¬ì¸µ
    "L5": 4000,   # ì „ë¬¸ ë¶„ì„
    "L6": 2500    # í†µê³„ ì¤‘ì‹¬
}

# ê¸°ì¡´ ë ˆë²¨ ë§¤í•‘
TOKEN_LIMITS_LEGACY = {
    "ì´ˆë“±": TOKEN_LIMITS_V3["L1"],
    "ì¼ë°˜ì¸": TOKEN_LIMITS_V3["L2"],
    "ì „ë¬¸ê°€": TOKEN_LIMITS_V3["L5"]
}

# ========================================
# Phase 104: ê´€ì ë³„ ìš”ì•½ ì‹œìŠ¤í…œ (ëª©ì /ì†Œì¬/ê³µë²•/íš¨ê³¼)
# íŠ¹í—ˆ ë¬¸ì„œ êµ¬ì¡° ê¸°ë°˜ ì²´ê³„ì  ë‹µë³€ ìƒì„±
# ========================================

PERSPECTIVE_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ íŠ¹í—ˆ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê²€ìƒ‰ëœ íŠ¹í—ˆ ì •ë³´ë¥¼ ë‹¤ìŒ 4ê°€ì§€ ê´€ì ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.

## 4ê°€ì§€ ê´€ì  ì •ì˜

1. **ëª©ì  (Purpose)**: íŠ¹í—ˆê°€ í•´ê²°í•˜ë ¤ëŠ” ê³¼ì œ/ë¬¸ì œ
   - ë°ì´í„° ì†ŒìŠ¤: objectko (í•´ê²°ê³¼ì œ) í•„ë“œ
   - ê¸°ì¡´ ê¸°ìˆ ì˜ í•œê³„, ë°œëª…ì´ í•„ìš”í•œ ì´ìœ 

2. **ì†Œì¬ (Material)**: ì‚¬ìš©ë˜ëŠ” ì£¼ìš” ì†Œì¬, ë¬¼ì§ˆ, ê¸°ìˆ  ìš”ì†Œ
   - ë°ì´í„° ì†ŒìŠ¤: IPC ë¶„ë¥˜ ë° ê¸°ìˆ  ì„¤ëª…ì—ì„œ ì¶”ë¡ 
   - í•µì‹¬ êµ¬ì„±ìš”ì†Œ, ì¬ë£Œ, ë¬¼ì§ˆ

3. **ê³µë²• (Method)**: êµ¬ì²´ì ì¸ ê¸°ìˆ  êµ¬í˜„ ë°©ë²•/ì ˆì°¨
   - ë°ì´í„° ì†ŒìŠ¤: solutionko (í•´ê²°ìˆ˜ë‹¨) í•„ë“œ
   - ì œì¡° ë°©ë²•, êµ¬í˜„ ì ˆì°¨, ê¸°ìˆ ì  ë‹¨ê³„

4. **íš¨ê³¼ (Effect)**: ê¸°ìˆ  ì ìš©ìœ¼ë¡œ ì¸í•œ ì„±ê³¼/ê°œì„ ì 
   - ë°ì´í„° ì†ŒìŠ¤: patent_abstc_ko (ì´ˆë¡)ì—ì„œ ì¶”ì¶œ
   - ì„±ëŠ¥ í–¥ìƒ, ë¹„ìš© ì ˆê°, í’ˆì§ˆ ê°œì„  ë“±

{level_instruction}

## ì‘ë‹µ í˜•ì‹ (JSON)
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

```json
{{
  "purpose": "ëª©ì  ì„¤ëª… (2-4ë¬¸ì¥)",
  "material": "ì†Œì¬ ì„¤ëª… (2-4ë¬¸ì¥)",
  "method": "ê³µë²• ì„¤ëª… (2-4ë¬¸ì¥)",
  "effect": "íš¨ê³¼ ì„¤ëª… (2-4ë¬¸ì¥)"
}}
```
"""

# ê´€ì ë³„ ë ˆë²¨ ì§€ì¹¨ (L1~L6)
PERSPECTIVE_LEVEL_INSTRUCTIONS = {
    "L1": """
**L1 (ì´ˆë“±í•™ìƒ) ìˆ˜ì¤€ ì„¤ëª…**:
- ëª¨ë“  ì „ë¬¸ìš©ì–´ë¥¼ ì‰¬ìš´ ë§ë¡œ ë°”ê¿” ì„¤ëª…
- ì¼ìƒìƒí™œ ë¹„ìœ  ì‚¬ìš© ("ë§ˆì¹˜ ~ì²˜ëŸ¼")
- ë¬¸ì¥ì„ ì§§ê²Œ (10ë‹¨ì–´ ì´ë‚´)
- ì´ëª¨ì§€ í™œìš© ê°€ëŠ¥ (ğŸ”‹âš¡ğŸš—ğŸ’¡)""",

    "L2": """
**L2 (ëŒ€í•™ìƒ/ì¼ë°˜ì¸) ìˆ˜ì¤€ ì„¤ëª…**:
- ì „ë¬¸ìš©ì–´ ì‚¬ìš©í•˜ë˜ ê´„í˜¸ ì•ˆì— ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€
- ì˜ˆ: "ì–‘ê·¹ì¬(ë°°í„°ë¦¬ì˜ ì–‘ê·¹ í™œë¬¼ì§ˆ)"
- í•™ìˆ ì  í‘œí˜„ ê°€ëŠ¥ ("~ì˜ ì›ë¦¬ëŠ”...", "~ì˜ íŠ¹ì„±ì€...")""",

    "L3": """
**L3 (ì‹¤ë¬´ì) ìˆ˜ì¤€ ì„¤ëª…**:
- ì‹¤ë¬´ ì ìš© ê´€ì ìœ¼ë¡œ ì„¤ëª…
- ì‚¬ì—…í™” ê°€ëŠ¥ì„±, ì‹œì¥ ê·œëª¨ ì–¸ê¸‰
- ì œí’ˆ/ê³µì •ê³¼ ì—°ê²°í•˜ì—¬ ì„¤ëª…""",

    "L4": """
**L4 (ì—°êµ¬ì) ìˆ˜ì¤€ ì„¤ëª…**:
- ê¸°ìˆ  ìš©ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì„¤ëª… ìµœì†Œí™”)
- ì¸¡ì • ë°©ë²•, ìˆ˜ì¹˜ ë²”ìœ„ í¬í•¨
- IPC ì„¸ë¶€ ì½”ë“œ í™œìš©
- ê¸°ìˆ  ê³µë°±/ê°œì„  ê°€ëŠ¥ì„± ì œì‹œ""",

    "L5": """
**L5 (ë³€ë¦¬ì‚¬/ì „ë¬¸ê°€) ìˆ˜ì¤€ ì„¤ëª…**:
- ë²•ë¥ /ì‹¬ì‚¬ ì „ë¬¸ ìš©ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- ê¶Œë¦¬ë²”ìœ„, ì„ í–‰ê¸°ìˆ  ë§¤í•‘
- íŠ¹í—ˆë²• ì¡°í•­ ì–¸ê¸‰ ê°€ëŠ¥
- ì¹¨í•´ ë¶„ì„ ê´€ì  í¬í•¨""",

    "L6": """
**L6 (ì •ì±…ë‹´ë‹¹ì) ìˆ˜ì¤€ ì„¤ëª…**:
- ê±°ì‹œì  ê´€ì ìœ¼ë¡œ ì„¤ëª…
- ì‚°ì—… ì „ì²´ ë§¥ë½, êµ­ê°€ë³„ ë¹„êµ
- ì •ì±…ì  ì‹œì‚¬ì  ë„ì¶œ
- ê¸°ìˆ ë¬´ì—­ìˆ˜ì§€, íŠ¹í—ˆ íŒ¨ë°€ë¦¬ ë“± ê±°ì‹œ ì§€í‘œ"""
}


def _extract_perspective_data(state: AgentState) -> dict:
    """íŠ¹í—ˆ ë°ì´í„°ì—ì„œ ê´€ì ë³„ ì›ì‹œ ë°ì´í„° ì¶”ì¶œ

    Args:
        state: í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ

    Returns:
        ê´€ì ë³„ ì›ì‹œ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    perspective_data = {
        "objectko_samples": [],
        "solutionko_samples": [],
        "abstc_samples": [],
        "ipc_codes": []
    }

    # RAG ê²°ê³¼ì—ì„œ ì¶”ì¶œ
    rag_results = state.get("rag_results", [])
    for result in rag_results[:5]:  # ìƒìœ„ 5ê°œë§Œ
        if isinstance(result, dict):
            metadata = result.get("metadata", {})
        else:
            metadata = getattr(result, "metadata", {}) or {}

        # Phase 104.1: sql_detailsì—ì„œë„ ë°ì´í„° ì¶”ì¶œ (RAG ê²°ê³¼ ë³´ê°• ì‹œ ì—¬ê¸°ì— ì €ì¥ë¨)
        sql_details = metadata.get("sql_details", {})

        # sql_details ìš°ì„ , ì—†ìœ¼ë©´ metadataì—ì„œ ì°¾ê¸°
        objectko = sql_details.get("objectko") or metadata.get("objectko")
        solutionko = sql_details.get("solutionko") or metadata.get("solutionko")
        patent_abstc_ko = sql_details.get("patent_abstc_ko") or metadata.get("patent_abstc_ko")
        ipc_main = sql_details.get("ipc_main") or metadata.get("ipc_main")

        if objectko:
            perspective_data["objectko_samples"].append(objectko[:500])
        if solutionko:
            perspective_data["solutionko_samples"].append(solutionko[:500])
        if patent_abstc_ko:
            perspective_data["abstc_samples"].append(patent_abstc_ko[:500])
        if ipc_main:
            perspective_data["ipc_codes"].append(ipc_main)

    # SQL ê²°ê³¼ì—ì„œ ì¶”ì¶œ
    sql_result = state.get("sql_result")
    if sql_result and hasattr(sql_result, "rows") and sql_result.rows:
        columns = sql_result.columns if hasattr(sql_result, "columns") else []
        col_map = {col.lower(): idx for idx, col in enumerate(columns)}

        for row in sql_result.rows[:5]:
            if "objectko" in col_map and row[col_map["objectko"]]:
                perspective_data["objectko_samples"].append(str(row[col_map["objectko"]])[:500])
            if "solutionko" in col_map and row[col_map["solutionko"]]:
                perspective_data["solutionko_samples"].append(str(row[col_map["solutionko"]])[:500])
            if "patent_abstc_ko" in col_map and row[col_map["patent_abstc_ko"]]:
                perspective_data["abstc_samples"].append(str(row[col_map["patent_abstc_ko"]])[:500])
            if "ipc_main" in col_map and row[col_map["ipc_main"]]:
                perspective_data["ipc_codes"].append(str(row[col_map["ipc_main"]]))

    return perspective_data


def _generate_perspective_summary(state: AgentState, llm, level: str) -> dict:
    """ê´€ì ë³„ ìš”ì•½ ìƒì„± - ì›ë³¸ ë°ì´í„° + ë ˆë²¨ë³„ ë¶€ì—° ì„¤ëª…

    Args:
        state: í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ
        llm: LLM í´ë¼ì´ì–¸íŠ¸
        level: ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ (L1~L6)

    Returns:
        ê´€ì ë³„ ìš”ì•½ ë”•ì…”ë„ˆë¦¬ {"purpose": {"original": ..., "explanation": ...}, ...}
    """
    perspective_data = _extract_perspective_data(state)

    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
    if not any(perspective_data.values()):
        logger.info("Phase 104: ê´€ì ë³„ ë°ì´í„° ì—†ìŒ - ìš”ì•½ ìƒì„± ìŠ¤í‚µ")
        return {}

    # ì›ë³¸ ë°ì´í„° êµ¬ì¡° ì´ˆê¸°í™”
    summary = {
        "purpose": {"original": "", "explanation": ""},
        "material": {"original": "", "explanation": ""},
        "method": {"original": "", "explanation": ""},
        "effect": {"original": "", "explanation": ""},
    }

    # ì›ë³¸ ë°ì´í„° ì¶”ì¶œ (ê²€ìƒ‰ëœ íŠ¹í—ˆ ë¬¸ì„œì—ì„œ)
    if perspective_data["objectko_samples"]:
        summary["purpose"]["original"] = perspective_data["objectko_samples"][0][:500]

    if perspective_data["solutionko_samples"]:
        solution = perspective_data["solutionko_samples"][0][:500]
        summary["material"]["original"] = solution
        summary["method"]["original"] = solution

    if perspective_data["abstc_samples"]:
        summary["effect"]["original"] = perspective_data["abstc_samples"][0][:500]

    # ì›ë³¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
    if not any(s["original"] for s in summary.values()):
        logger.info("Phase 104: ì›ë³¸ ë°ì´í„° ì—†ìŒ - ìš”ì•½ ìƒì„± ìŠ¤í‚µ")
        return {}

    # ë ˆë²¨ë³„ ë¶€ì—° ì„¤ëª… ìƒì„± (LLM ì‚¬ìš©)
    try:
        explanations = _generate_level_explanations(summary, llm, level)
        for key in summary:
            if key in explanations and explanations[key]:
                summary[key]["explanation"] = explanations[key]
        logger.info(f"Phase 104: ê´€ì ë³„ ìš”ì•½ ìƒì„± ì™„ë£Œ - ë ˆë²¨ {level}")
    except Exception as e:
        logger.warning(f"Phase 104: ë¶€ì—° ì„¤ëª… ìƒì„± ì‹¤íŒ¨ (ì›ë³¸ ë°ì´í„°ëŠ” ìœ ì§€) - {e}")

    return summary


def _generate_level_explanations(summary: dict, llm, level: str) -> dict:
    """ë ˆë²¨ì— ë§ëŠ” ë¶€ì—° ì„¤ëª… ìƒì„±

    Args:
        summary: ì›ë³¸ ë°ì´í„°ê°€ í¬í•¨ëœ ìš”ì•½ ë”•ì…”ë„ˆë¦¬
        llm: LLM í´ë¼ì´ì–¸íŠ¸
        level: ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ (L1~L6)

    Returns:
        ì„¤ëª… ë”•ì…”ë„ˆë¦¬ {"purpose": "...", "material": "...", "method": "...", "effect": "..."}
    """
    import json
    import re

    # ë ˆë²¨ë³„ ìŠ¤íƒ€ì¼ê³¼ ë¶„ëŸ‰ ê°€ì´ë“œ
    level_configs = {
        "L1": {
            "style": "ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ë¹„ìœ ì™€ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ê²Œ",
            "length": "2~3ë¬¸ì¥ (80~120ì)",
            "example": "ğŸ”‹ ë°°í„°ë¦¬ëŠ” ì „ê¸°ë¥¼ ì €ì¥í•˜ëŠ” í†µì´ì—ìš”! ì´ ê¸°ìˆ ì€ ê·¸ í†µì„ ë” í¬ê³  íŠ¼íŠ¼í•˜ê²Œ ë§Œë“¤ì–´ì„œ í•¸ë“œí°ì´ë‚˜ ì „ê¸°ì°¨ê°€ ë” ì˜¤ë˜ ê°ˆ ìˆ˜ ìˆê²Œ í•´ì¤˜ìš”."
        },
        "L2": {
            "style": "ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆê²Œ ì „ë¬¸ìš©ì–´ëŠ” í’€ì–´ì„œ ì„¤ëª…í•˜ë©°",
            "length": "2~3ë¬¸ì¥ (100~150ì)",
            "example": "ë¦¬íŠ¬ì´ì˜¨ ë°°í„°ë¦¬ì˜ ì–‘ê·¹ì¬ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì–‘ê·¹ì¬ëŠ” ë°°í„°ë¦¬ì—ì„œ ì „ê¸°ë¥¼ ì €ì¥í•˜ëŠ” í•µì‹¬ ë¶€í’ˆìœ¼ë¡œ, ì´ ê¸°ìˆ ì„ í†µí•´ ì¶©ì „ ìš©ëŸ‰ê³¼ ìˆ˜ëª…ì´ ê°œì„ ë©ë‹ˆë‹¤."
        },
        "L3": {
            "style": "ì¤‘ì†Œê¸°ì—… ì‹¤ë¬´ìê°€ ì‚¬ì—…í™” ê´€ì ì—ì„œ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‹¤ìš©ì ìœ¼ë¡œ",
            "length": "2~3ë¬¸ì¥ (100~150ì)",
            "example": "ê¸°ì¡´ ê³µì • ëŒ€ë¹„ ì œì¡° ë¹„ìš©ì„ 20% ì ˆê°í•˜ë©´ì„œ ì„±ëŠ¥ì€ ìœ ì§€í•˜ëŠ” ì–‘ê·¹ì¬ ì œì¡° ê¸°ìˆ ì…ë‹ˆë‹¤. ê¸°ì¡´ ì„¤ë¹„ë¥¼ í™œìš©í•  ìˆ˜ ìˆì–´ ì´ˆê¸° íˆ¬ì ë¶€ë‹´ì´ ë‚®ìŠµë‹ˆë‹¤."
        },
        "L4": {
            "style": "ì—°êµ¬ìê°€ ê¸°ìˆ ì  íŠ¹ì§•ì„ íŒŒì•…í•  ìˆ˜ ìˆê²Œ ì •í™•í•œ ìš©ì–´ë¥¼ ì‚¬ìš©í•´ì„œ",
            "length": "2~3ë¬¸ì¥ (100~150ì)",
            "example": "NCM ì–‘ê·¹ì¬ì˜ Ni í•¨ëŸ‰ì„ 80% ì´ìƒìœ¼ë¡œ ë†’ì´ë©´ì„œ ì—´ì•ˆì •ì„±ì„ í™•ë³´í•˜ëŠ” í‘œë©´ ì½”íŒ… ê¸°ìˆ ì…ë‹ˆë‹¤. Alâ‚‚Oâ‚ƒ ë‚˜ë…¸ì½”íŒ…ìœ¼ë¡œ ê³„ë©´ ì €í•­ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤."
        },
        "L5": {
            "style": "ë³€ë¦¬ì‚¬/ì‹¬ì‚¬ê´€ì´ ê¶Œë¦¬ë²”ìœ„ì™€ ì§„ë³´ì„±ì„ íŒŒì•…í•  ìˆ˜ ìˆê²Œ ë²•ì  ê´€ì ì—ì„œ",
            "length": "2~3ë¬¸ì¥ (100~150ì)",
            "example": "ì²­êµ¬í•­ 1ì˜ êµ¬ì„±ìš”ì†Œ ì¡°í•©ì´ ì„ í–‰ê¸°ìˆ  ëŒ€ë¹„ ì—ë„ˆì§€ ë°€ë„ 15% í–¥ìƒì˜ í˜„ì €í•œ íš¨ê³¼ë¥¼ ë‚˜íƒ€ë‚´ì–´ ì§„ë³´ì„±ì´ ì¸ì •ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        },
        "L6": {
            "style": "ì •ì±…ë‹´ë‹¹ìê°€ ì‚°ì—…ì  íŒŒê¸‰íš¨ê³¼ë¥¼ ì´í•´í•  ìˆ˜ ìˆê²Œ ê±°ì‹œì ìœ¼ë¡œ",
            "length": "2~3ë¬¸ì¥ (100~150ì)",
            "example": "êµ­ë‚´ ì´ì°¨ì „ì§€ ì†Œì¬ ìë¦½ë„ë¥¼ ë†’ì´ëŠ” í•µì‹¬ ê¸°ìˆ ë¡œ, ì¼ë³¸/ì¤‘êµ­ ì˜ì¡´ë„ë¥¼ ë‚®ì¶”ê³  êµ­ë‚´ ì†Œì¬ ê¸°ì—…ì˜ ê²½ìŸë ¥ ê°•í™”ì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        },
    }

    config = level_configs.get(level, level_configs["L2"])

    prompt = f"""ì•„ë˜ íŠ¹í—ˆ ì›ë¬¸ì„ ì½ê³ , {config["style"]} ë¶€ì—° ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì›ë¬¸ - ëª©ì /í•´ê²°ê³¼ì œ]
{summary["purpose"]["original"][:300] or "(ì •ë³´ ì—†ìŒ)"}

[ì›ë¬¸ - ì†Œì¬/êµ¬ì„±]
{summary["material"]["original"][:300] or "(ì •ë³´ ì—†ìŒ)"}

[ì›ë¬¸ - íš¨ê³¼]
{summary["effect"]["original"][:300] or "(ì •ë³´ ì—†ìŒ)"}

[ì‘ì„± ê°€ì´ë“œ]
- ë¶„ëŸ‰: ê° í•­ëª©ë‹¹ {config["length"]}
- ì›ë¬¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- ì˜ˆì‹œ í†¤: "{config["example"][:50]}..."

[ì¶œë ¥ í˜•ì‹ - JSONë§Œ ì¶œë ¥]
{{"purpose": "ëª©ì  ì„¤ëª…...", "material": "ì†Œì¬ ì„¤ëª…...", "method": "ë°©ë²• ì„¤ëª…...", "effect": "íš¨ê³¼ ì„¤ëª…..."}}"""

    try:
        response = llm.generate(prompt=prompt, max_tokens=800, temperature=0.4)

        # JSON íŒŒì‹± (ì¤‘ì²© ê°ì²´ í—ˆìš©)
        json_match = re.search(r'\{[^{}]*"purpose"[^{}]*\}', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())

        # ë” ë„“ì€ íŒ¨í„´ ì‹œë„
        json_match = re.search(r'\{.*?\}', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
    except json.JSONDecodeError as e:
        logger.warning(f"Phase 104: ë¶€ì—° ì„¤ëª… JSON íŒŒì‹± ì‹¤íŒ¨ - {e}")
    except Exception as e:
        logger.warning(f"Phase 104: ë¶€ì—° ì„¤ëª… ìƒì„± ì˜ˆì™¸ - {e}")

    return {}


# ê°„ë‹¨í•œ ì‘ë‹µìš© í”„ë¡¬í”„íŠ¸
SIMPLE_RESPONSE_PROMPT = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ R&D ë°ì´í„° ë¶„ì„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
- ì¸ì‚¬ì—ëŠ” ì¸ì‚¬ë¡œ ë‹µí•˜ì„¸ìš”
- ë„ì›€ì´ í•„ìš”í•˜ë©´ ê°€ëŠ¥í•œ ê¸°ëŠ¥ì„ ì•ˆë‚´í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”

ê°€ëŠ¥í•œ ê¸°ëŠ¥:
1. ì—°êµ¬ê³¼ì œ/íŠ¹í—ˆ/ì œì•ˆì„œ ê²€ìƒ‰ (ì˜ˆ: "ì¸ê³µì§€ëŠ¥ ê´€ë ¨ íŠ¹í—ˆ ì•Œë ¤ì¤˜")
2. ë°ì´í„° ì¡°íšŒ (ì˜ˆ: "ì˜ˆì‚°ì´ í° ê³¼ì œ 10ê°œ")
3. ì—°êµ¬ ë™í–¥ ë¶„ì„ (ì˜ˆ: "ë¸”ë¡ì²´ì¸ ì—°êµ¬ ë™í–¥ì€?")
"""


# Phase 50: _get_subtype_prompt í•¨ìˆ˜ ì‚­ì œ (SYSTEM_PROMPTì— í†µí•©)


def generate_response(state: AgentState) -> AgentState:
    """ì‘ë‹µ ìƒì„± ë…¸ë“œ

    ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„±.

    Args:
        state: í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ

    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (response, conversation_history)
    """
    query = state.get("query", "")
    query_type = state.get("query_type", "simple")

    try:
        llm = get_llm_client()

        if query_type == "simple":
            # ê°„ë‹¨í•œ ì‘ë‹µ
            response = llm.generate(
                prompt=query,
                system_prompt=SIMPLE_RESPONSE_PROMPT,
                max_tokens=500,
                temperature=0.3  # ì‘ë‹µ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì¶¤
            )
        else:
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ
            context = build_merged_context(state)
            query_intent = state.get("query_intent", "")

            # ê²€ìƒ‰ ê²°ê³¼ ì—†ì„ ë•Œ LLM ìì²´ ì§€ì‹ ì‚¬ìš© (Phase 8)
            no_results = (
                context == "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤." or
                context.strip() == "" or
                "ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" in context
            )

            # Phase 8.5: ê°œë… ì„¤ëª… ì§ˆë¬¸ì¸ë° ì»¨í…ìŠ¤íŠ¸ê°€ ë¹ˆì•½í•œ ê²½ìš°
            is_concept = _is_concept_question(query, query_intent)
            context_meaningful = _is_context_meaningful(context)
            use_llm_knowledge = no_results or (is_concept and not context_meaningful)

            # Phase 51: query_subtypeì„ ë¯¸ë¦¬ ê°€ì ¸ì˜´ (í”„ë¡¬í”„íŠ¸ ì„ íƒìš©)
            query_subtype = state.get("query_subtype", "list")

            # Phase 52: SQL ê²°ê³¼ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜´ (í”„ë¡¬í”„íŠ¸ ì„ íƒìš©)
            multi_sql_results = state.get("multi_sql_results")
            sql_result = state.get("sql_result")

            # Phase 69: entity_typesë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜´ (í˜‘ì—… ê¸°ê´€ ì¶”ì²œ íŒë³„ìš©)
            entity_types = state.get("entity_types", [])

            # Phase 94: ES Scout domain_hits ì •ë³´ ê°€ì ¸ì˜´
            domain_hits = state.get("domain_hits", {})

            # Phase 99.5/99.6: ES í†µê³„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì§ì ‘ í…Œì´ë¸” ìƒì„±
            es_statistics = state.get("es_statistics")
            statistics_type = state.get("statistics_type")
            # Phase 99.5/99.6 í™•ì¸ (ë””ë²„ê·¸ ì œê±°ë¨)

            # Phase 99.6: crosstab_analysis (ì¶œì›ê¸°ê´€ë³„ ì—°ë„ë³„ í¬ë¡œìŠ¤íƒ­)
            if es_statistics and statistics_type == "crosstab_analysis":
                crosstab_context = _build_crosstab_context(es_statistics, query)
                user_prompt = f"""## í¬ë¡œìŠ¤íƒ­ í†µê³„ ë°ì´í„° (Elasticsearch ì§‘ê³„)
{crosstab_context}

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ìœ„ ì¶œì›ê¸°ê´€ë³„ ì—°ë„ë³„ í¬ë¡œìŠ¤íƒ­ í†µê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. ì£¼ì œ ì†Œê°œ (1-2ë¬¸ì¥)
2. ì¶œì›ê¸°ê´€ ìˆœìœ„ í‘œ (ìœ„ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ê·¸ëŒ€ë¡œ ì‚¬ìš©)
3. í•µì‹¬ ë¶„ì„:
   - TOP 3 ê¸°ê´€ì˜ íŠ¹ì§• ë° ì¶œì› íŒ¨í„´
   - ìµœê·¼ ì—°ë„ì— ê¸‰ì¦í•œ ê¸°ê´€ ì–¸ê¸‰
   - ì¶œì› ì§‘ì¤‘ë„ ë¶„ì„ (ìƒìœ„ ê¸°ê´€ ë¹„ì¤‘)
4. ì‹œì‚¬ì  (1-2ë¬¸ì¥)"""

                logger.info(f"Phase 99.6: ES í¬ë¡œìŠ¤íƒ­ ê¸°ë°˜ ì‘ë‹µ ìƒì„±")

                response = llm.generate(
                    prompt=user_prompt,
                    system_prompt=SYSTEM_PROMPT,
                    max_tokens=2500,
                    temperature=0.3
                )

                return {
                    **state,
                    "response": response,
                    "response_source": "es_crosstab",
                }

            # Phase 99.5: trend_analysis (ì—°ë„ë³„ í†µê³„)
            if es_statistics and statistics_type == "trend_analysis":
                # ES í†µê³„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜
                stats_context = _build_statistics_context(es_statistics, query)
                user_prompt = f"""## í†µê³„ ë°ì´í„° (Elasticsearch ì§‘ê³„)
{stats_context}

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ìœ„ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. ì£¼ì œ ì†Œê°œ (1-2ë¬¸ì¥)
2. ì—°ë„ë³„ ì¶”ì´ í‘œ (ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”)
3. í•µì‹¬ ë¶„ì„:
   - ìµœê·¼ 3ë…„ê°„ í‰ê·  vs ì´ì „ 3ë…„ê°„ í‰ê·  ë¹„êµ
   - ì¦ê°€/ê°ì†Œ ì¶”ì„¸ í•´ì„
   - CAGR(ì—°í‰ê·  ì„±ì¥ë¥ ) ê³„ì‚° (ê°€ëŠ¥í•œ ê²½ìš°)
4. ì‹œì‚¬ì  (1-2ë¬¸ì¥)"""

                logger.info(f"Phase 99.5: ES í†µê³„ ê¸°ë°˜ ì‘ë‹µ ìƒì„± - {len(es_statistics)}ê°œ ì—”í‹°í‹°")

                # í†µê³„ ì „ìš© í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„±
                response = llm.generate(
                    prompt=user_prompt,
                    system_prompt=SYSTEM_PROMPT,
                    max_tokens=2000,
                    temperature=0.3
                )

                return {
                    **state,
                    "response": response,
                    "response_source": "es_statistics",
                }

            if use_llm_knowledge:
                user_prompt = f"""## ê²€ìƒ‰ ê²°ê³¼
ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë¯€ë¡œ, ë‹¹ì‹ ì´ ì•Œê³  ìˆëŠ” ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ ì‹œì‘ ì‹œ ë°˜ë“œì‹œ "**ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ì„œ ì œê°€ ì•„ëŠ” ì§€ì‹ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.**"ë¼ê³  ë¨¼ì € ì–¸ê¸‰í•˜ì„¸ìš”.
ê·¸ í›„ ì§ˆë¬¸ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì„¤ëª…ì´ë‚˜ ê°œë…ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
                if is_concept and not context_meaningful:
                    logger.info(f"ê°œë… ì§ˆë¬¸ + ë¹ˆì•½í•œ ì»¨í…ìŠ¤íŠ¸ - LLM ìì²´ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ (is_concept={is_concept})")
                else:
                    logger.info("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - LLM ìì²´ ì§€ì‹ìœ¼ë¡œ ë‹µë³€")
            else:
                # ê²°ê³¼ ìˆ˜ ê³„ì‚°
                # Phase 50: ë™ì  ì§€ì¹¨ ê°„ì†Œí™” (í† í° ì ˆê°)
                if multi_sql_results:
                    # ë‹¤ì¤‘ ì—”í‹°í‹° ê²°ê³¼ - ê°„ê²°í•œ ì§€ì¹¨
                    entity_counts = []
                    for entity_type, result in multi_sql_results.items():
                        if result.success and result.row_count > 0:
                            from sql.sql_prompts import ENTITY_LABELS
                            label = ENTITY_LABELS.get(entity_type, entity_type)
                            entity_counts.append(f"{label} {result.row_count}ê±´")

                    # Phase 94: domain_hits ê¸°ë°˜ ë„ë©”ì¸ë³„ ë¶„ë¦¬ í‘œì‹œ ì§€ì¹¨
                    if domain_hits:
                        active_domains = [d for d, count in domain_hits.items() if count > 0]
                        domain_labels = {"patent": "íŠ¹í—ˆ", "project": "ê³¼ì œ", "equipment": "ì¥ë¹„", "proposal": "ì œì•ˆ"}
                        domain_str = ", ".join(domain_labels.get(d, d) for d in active_domains)
                        result_instruction = f"[Phase 94: ES Scout ê¸°ë°˜ ë©€í‹° ë„ë©”ì¸ ê²€ìƒ‰: {domain_str}]\n[{', '.join(entity_counts)} - ë„ë©”ì¸ë³„ ë¶„ë¦¬ í‘œ ì‘ì„±]"
                        logger.info(f"Phase 94: ë„ë©”ì¸ë³„ ë¶„ë¦¬ í‘œ ì§€ì¹¨ ìƒì„± - {active_domains}")
                    else:
                        result_instruction = f"[ë‹¤ì¤‘ ì—”í‹°í‹°: {', '.join(entity_counts)} - ìœ í˜•ë³„ ë³„ë„ í‘œ]"
                else:
                    row_count = sql_result.row_count if sql_result and hasattr(sql_result, 'row_count') else 0
                    result_instruction = f"[{row_count}ê±´ ì „ì²´ í‘œë¡œ ì¶œë ¥]" if row_count > 0 else ""

                # ë¹„êµ ë¶„ì„ ì§€ì¹¨ - ê°„ì†Œí™”
                comparison_instruction = ""
                if query_subtype == "comparison":
                    structured_keywords = state.get("structured_keywords", {})
                    comparison_targets = structured_keywords.get("filter", []) if structured_keywords else []
                    targets = ', '.join(comparison_targets) if comparison_targets else 'ì»¨í…ìŠ¤íŠ¸ ì°¸ì¡°'
                    comparison_instruction = f"[ë¹„êµ ë¶„ì„: {targets}]"

                # Phase 95: ê·¸ë˜í”„ ê´€ê³„ ì •ë³´ ì¶”ê°€
                # Phase 103.2: graph_context ì¤‘ë³µ ë°©ì§€ - contextì— ì´ë¯¸ RAG ì •ë³´ í¬í•¨
                rag_results = state.get("rag_results", [])
                # graph_context = _build_graph_context_for_prompt(rag_results)  # ì¤‘ë³µ ì œê±°
                # if graph_context:
                #     logger.info(f"Phase 95: ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ë¨ ({len(rag_results)}ê±´ RAG ê²°ê³¼ì—ì„œ)")

                user_prompt = f"""## ì»¨í…ìŠ¤íŠ¸
{context}
{result_instruction}{comparison_instruction}

## ì§ˆë¬¸
{query}"""

            # Phase 52: subtypeë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            # SQL ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì¥ë¹„ ì¶”ì²œ ë“±ì€ í‘œë¡œ ë³´ì—¬ì¤˜ì•¼ í•¨)
            has_sql_results = (
                (sql_result and sql_result.row_count > 0) or
                (multi_sql_results and any(r.row_count > 0 for r in multi_sql_results.values() if r.success))
            )

            # Phase 62/69/86: ì¶”ì²œ ì¿¼ë¦¬ ë¶„ê¸° (ê¸°ìˆ ë¶„ë¥˜ vs í˜‘ì—… ê¸°ê´€ vs ì¥ë¹„)
            if query_subtype == "recommendation":
                # Phase 69: í˜‘ì—… ê¸°ê´€ ì¶”ì²œ ê°ì§€
                is_collaboration = any(kw in query for kw in COLLABORATION_KEYWORDS)
                is_tech_classification = "ë¶„ë¥˜" in query or "tech" in entity_types
                # Phase 86: ì¥ë¹„ ì¶”ì²œ ê°ì§€ - entity_typesì— equipì´ ìˆê±°ë‚˜ ì¥ë¹„ ê´€ë ¨ í‚¤ì›Œë“œ
                is_equipment = "equip" in entity_types or any(
                    kw in query for kw in ["ì¥ë¹„", "ì¸¡ì •", "ì‹œí—˜ê¸°", "ë¶„ì„ê¸°", "equipment"]
                )

                if is_collaboration and not is_tech_classification and not is_equipment:
                    selected_prompt = COLLABORATION_PROMPT
                    logger.info(f"Phase 69: í˜‘ì—… ê¸°ê´€ ì¶”ì²œ ì¿¼ë¦¬ - COLLABORATION_PROMPT ì‚¬ìš© (SQLê²°ê³¼: {has_sql_results})")
                elif is_equipment and not is_tech_classification:
                    # Phase 86: ì¥ë¹„ ì¶”ì²œ
                    selected_prompt = EQUIPMENT_PROMPT
                    logger.info(f"Phase 86: ì¥ë¹„ ì¶”ì²œ ì¿¼ë¦¬ - EQUIPMENT_PROMPT ì‚¬ìš© (SQLê²°ê³¼: {has_sql_results})")
                else:
                    selected_prompt = RECOMMENDATION_PROMPT
                    logger.info(f"Phase 62: ê¸°ìˆ ë¶„ë¥˜ ì¶”ì²œ ì¿¼ë¦¬ - RECOMMENDATION_PROMPT ì‚¬ìš© (SQLê²°ê³¼: {has_sql_results})")
            elif query_subtype in SUBTYPE_PROMPTS:
                selected_prompt = SYSTEM_PROMPT + "\n\n## ì¶”ê°€ ì§€ì¹¨\n" + SUBTYPE_PROMPTS[query_subtype]
                logger.info(f"{query_subtype} ì¿¼ë¦¬ - ì¶”ê°€ ì§€ì¹¨ ì ìš©")
            else:
                selected_prompt = SYSTEM_PROMPT
                if has_sql_results:
                    logger.info(f"SQL ê²°ê³¼ {sql_result.row_count if sql_result else 0}ê±´ - SYSTEM_PROMPT ì‚¬ìš© (í‘œ ì¶œë ¥)")

            # Phase 54/70/73.2/92: ë‹¤ì¤‘ ì—”í‹°í‹°/ë„ë©”ì¸ ëŒ€ì‘ - max_tokens ë™ì  ì¡°ì •
            is_collaboration = query_subtype == "recommendation" and any(
                kw in query for kw in ["í˜‘ì—…", "í˜‘ë ¥", "íŒŒíŠ¸ë„ˆ", "ê³µë™ì—°êµ¬"]
            )
            is_nationality_ranking = query_subtype == "nationality_ranking"
            # Phase 92: ìš°ëŒ€/ê°ì  ì •ë³´ëŠ” ìš°ëŒ€ í‘œ + ê°ì  í‘œ + ìš”ì•½ í•„ìš”
            is_evalp_pref = query_subtype == "evalp_pref" or any(
                kw in query for kw in ["ìš°ëŒ€", "ê°ì ", "ê°€ì ", "ìš°ëŒ€ê°ì "]
            )

            if multi_sql_results and len(multi_sql_results) > 1:
                response_max_tokens = 2048  # ë‹¤ì¤‘ ì—”í‹°í‹°: í‘œ ì—¬ëŸ¬ ê°œ + ì†Œê²°
            elif is_collaboration:
                response_max_tokens = 3072  # Phase 70: ë‹¤ì¤‘ ë„ë©”ì¸ í˜‘ì—… ì¶”ì²œ (í‘œ2ê°œ+ì´í‰)
            elif is_nationality_ranking:
                response_max_tokens = 2048  # Phase 73.2: ìêµ­ í‘œ + íƒ€êµ­ í‘œ + ì¸ì‚¬ì´íŠ¸
            elif is_evalp_pref:
                response_max_tokens = 4096  # Phase 92: ìš°ëŒ€ í‘œ + ê°ì  í‘œ + ìš”ì•½ (3072â†’4096 ì¦ê°€)
            else:
                response_max_tokens = 1024  # ë‹¨ì¼ ì—”í‹°í‹°: ê¸°ì¡´ ìœ ì§€

            # Phase 92.1: ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
            logger.info(f"Phase 92 ë””ë²„ê¹…: query_subtype={query_subtype}, is_evalp_pref={is_evalp_pref}, max_tokens={response_max_tokens}")

            # Phase 90: ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            # sources ì¶”ì¶œ: sql_result ë° multi_sql_resultsì—ì„œ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            context_sources = []
            if sql_result and hasattr(sql_result, 'row_count') and sql_result.row_count > 0:
                context_sources.append({
                    'type': 'sql',
                    'score': 1.0,  # SQL ê²°ê³¼ëŠ” ì‹ ë¢°ë„ ë†’ìŒ
                    'cross_validated': True
                })
            if multi_sql_results:
                for entity_type, result in multi_sql_results.items():
                    if result.success and result.row_count > 0:
                        context_sources.append({
                            'type': f'sql_{entity_type}',
                            'score': 1.0,
                            'cross_validated': True
                        })

            # RAG ì†ŒìŠ¤ ì¶”ì¶œ (stateì—ì„œ)
            rag_results = state.get("rag_results", [])
            for rag_item in rag_results:
                if isinstance(rag_item, dict):
                    context_sources.append({
                        'type': rag_item.get('source', 'rag'),
                        'score': rag_item.get('score', 0.5),
                        'cross_validated': rag_item.get('cross_validated', False)
                    })

            context_quality = _calculate_context_quality(context, context_sources)
            logger.info(f"Phase 90: ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ = {context_quality:.2f} (ì†ŒìŠ¤ {len(context_sources)}ê°œ)")

            # í’ˆì§ˆ ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ê²½ê³  ë¡œê·¸
            if context_quality < 0.3:
                logger.warning(f"Phase 90: ë‚®ì€ ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ({context_quality:.2f}) - í™˜ê° ìœ„í—˜ ì£¼ì˜")

            # Phase 103: v1.3 ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ ì ìš© (L1~L6)
            level = state.get("level", "ì¼ë°˜ì¸")

            # ë ˆë²¨ í”„ë¡¬í”„íŠ¸ ì„ íƒ (V3 ìš°ì„ , ê¸°ì¡´ ë ˆë²¨ fallback)
            if level in LEVEL_PROMPTS_V3:
                # V3 ë ˆë²¨ (L1~L6)
                level_prompt = LEVEL_PROMPTS_V3[level]
                level_max_tokens = TOKEN_LIMITS_V3[level]
                logger.info(f"Phase 103: v1.3 ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ ì ìš© - {level}")
            elif level in LEVEL_PROMPTS:
                # ê¸°ì¡´ ë ˆë²¨ (ì´ˆë“±, ì¼ë°˜ì¸, ì „ë¬¸ê°€)
                level_prompt = LEVEL_PROMPTS[level]
                level_max_tokens = TOKEN_LIMITS_LEGACY[level]
                logger.info(f"Phase 103: ê¸°ì¡´ ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ ì ìš© - {level}")
            else:
                # ê¸°ë³¸ê°’
                level_prompt = LEVEL_PROMPTS_V3["L2"]
                level_max_tokens = TOKEN_LIMITS_V3["L2"]
                logger.warning(f"Phase 103: ì•Œ ìˆ˜ ì—†ëŠ” ë ˆë²¨ '{level}', L2(ì¼ë°˜ì¸) ê¸°ë³¸ê°’ ì‚¬ìš©")

            # Phase 102: ìì²´ ì§€ì‹ ê¸ˆì§€ ê·œì¹™ + ë ˆë²¨ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©
            final_prompt = f"{selected_prompt}\n\n{NO_HALLUCINATION_RULE}\n\n## ë‹µë³€ ìˆ˜ì¤€ ì§€ì¹¨\n{level_prompt}"

            # Phase 103: max_tokens ìš°ì„ ìˆœìœ„
            # 1. ë‹¤ì¤‘ ì—”í‹°í‹°/ë„ë©”ì¸ ëŒ€ì‘ (response_max_tokens)
            # 2. ë ˆë²¨ë³„ ì œí•œ (level_max_tokens)
            # ë†’ì€ ê°’ ì‚¬ìš© (ì¶©ë¶„í•œ ì‘ë‹µ ê¸¸ì´ ë³´ì¥)
            final_max_tokens = max(response_max_tokens, level_max_tokens)
            logger.info(f"Phase 103: max_tokens = max(response={response_max_tokens}, level={level_max_tokens}) = {final_max_tokens}")

            response = llm.generate(
                prompt=user_prompt,
                system_prompt=final_prompt,
                max_tokens=final_max_tokens,
                temperature=0.3
            )

            # Phase 104: ê´€ì ë³„ ìš”ì•½ ìƒì„± (íŠ¹í—ˆ ê²€ìƒ‰ ì¿¼ë¦¬ì—ë§Œ ì ìš©)
            # Phase 104.2: SQL ê²°ê³¼ ë˜ëŠ” RAG ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê´€ì ë³„ ìš”ì•½ ì‹œë„
            perspective_summary = {}
            entity_types = state.get("entity_types", [])
            is_patent_query = "patent" in entity_types or query_type in ["sql", "rag", "hybrid"]
            has_rag_results = bool(state.get("rag_results"))
            has_sql_result = bool(state.get("sql_result"))
            rag_results_count = len(state.get("rag_results", []))

            logger.info(f"Phase 104 ì¡°ê±´ ê²€ì‚¬: entity_types={entity_types}, query_type={query_type}, is_patent_query={is_patent_query}, has_rag_results={has_rag_results}, has_sql_result={has_sql_result}, rag_count={rag_results_count}")

            # SQL ê²°ê³¼ ë˜ëŠ” RAG ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê´€ì ë³„ ìš”ì•½ ìƒì„± ì‹œë„
            if is_patent_query and (has_rag_results or has_sql_result):
                try:
                    perspective_summary = _generate_perspective_summary(state, llm, level)
                    if perspective_summary:
                        logger.info(f"Phase 104: ê´€ì ë³„ ìš”ì•½ ìƒì„± ì„±ê³µ - {list(perspective_summary.keys())}")
                except Exception as e:
                    logger.error(f"Phase 104: ê´€ì ë³„ ìš”ì•½ ìƒì„± ì‹¤íŒ¨ (ë©”ì¸ ì‘ë‹µì€ ì •ìƒ) - {e}")

        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        new_messages = [
            ChatMessage(role="user", content=query),
            ChatMessage(role="assistant", content=response)
        ]

        logger.info(f"ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response)}ì, ì‹ ë¢°ë„: {context_quality:.2f}")

        return {
            **state,
            "response": response,
            "context_quality": context_quality,  # Phase 102: ì‹ ë¢°ë„ ì ìˆ˜ ë°˜í™˜
            "perspective_summary": perspective_summary,  # Phase 104: ê´€ì ë³„ ìš”ì•½
            "conversation_history": new_messages
        }

    except Exception as e:
        logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        error_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

        return {
            **state,
            "response": error_response,
            "error": str(e),
            "conversation_history": [
                ChatMessage(role="user", content=query),
                ChatMessage(role="assistant", content=error_response)
            ]
        }
