"""
ì‘ë‹µ ìƒì„± ë…¸ë“œ
- LLMì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import logging
from typing import Dict, Any

from workflow.state import AgentState, ChatMessage
from workflow.nodes.merger import build_merged_context
from llm.llm_client import get_llm_client

logger = logging.getLogger(__name__)


def _is_concept_question(query: str, query_intent: str) -> bool:
    """ê°œë… ì„¤ëª… ìš”ì²­ì¸ì§€ í™•ì¸

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        query_intent: ë¶„ì„ëœ ì§ˆë¬¸ ì˜ë„

    Returns:
        ê°œë… ì„¤ëª… ìš”ì²­ ì—¬ë¶€
    """
    concept_patterns = ["ë€?", "ì´ë€?", "ë­ì•¼", "ë¬´ì—‡", "ì„¤ëª…í•´", "ë­”ê°€ìš”", "ë­ì—ìš”", "ì´ë€", "ì´ ë­"]
    intent_keywords = ["ê°œë…", "ì„¤ëª…", "ì •ì˜", "ì˜ë¯¸"]

    return (
        any(p in query for p in concept_patterns) or
        any(k in query_intent for k in intent_keywords)
    )


def _is_context_meaningful(context: str) -> bool:
    """ì»¨í…ìŠ¤íŠ¸ê°€ ì˜ë¯¸ ìˆëŠ” ì •ë³´ì¸ì§€ í™•ì¸

    ìˆ«ì IDë§Œ ìˆê³  ì‹¤ì œ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ê°ì§€

    Args:
        context: ë³‘í•©ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´

    Returns:
        ì˜ë¯¸ ìˆëŠ” ì •ë³´ í¬í•¨ ì—¬ë¶€
    """
    if not context or context == "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
        return False

    # ë‚´ìš©ì´ ìˆëŠ” ì¤„ ìˆ˜ í™•ì¸ (IDë§Œ ìˆëŠ” ì¤„ ì œì™¸)
    lines = [l.strip() for l in context.split('\n') if l.strip()]

    # ì˜ë¯¸ ìˆëŠ” ì¤„: 30ì ì´ìƒì´ê³ , ìˆ«ì/íŒŒì´í”„ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§€ì§€ ì•Šì€ ì¤„
    content_lines = []
    for line in lines:
        # í…Œì´ë¸” êµ¬ë¶„ì„  ì œì™¸
        if line.replace('-', '').replace('|', '').strip() == '':
            continue
        # ìˆœìˆ˜ ìˆ«ì ID ì¤„ ì œì™¸
        cleaned = line.replace('|', '').replace('[', '').replace(']', '').strip()
        if cleaned.isdigit():
            continue
        # 30ì ì´ìƒì˜ ì‹¤ì œ ë‚´ìš©ì´ ìˆëŠ” ì¤„
        if len(line) > 30:
            content_lines.append(line)

    return len(content_lines) >= 3


def _build_statistics_context(es_statistics: dict, query: str) -> str:
    """Phase 99.5: ES í†µê³„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

    Args:
        es_statistics: ES entity_statistics() ê²°ê³¼
            {
                "patent": {"total": 1234, "buckets": [{"key": "2024", "count": 100}, ...]},
                "project": {...}
            }
        query: ì‚¬ìš©ì ì§ˆë¬¸ (ì»¨í…ìŠ¤íŠ¸ìš©)

    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ í†µê³„ ì»¨í…ìŠ¤íŠ¸
    """
    lines = []

    for entity_type, stats in es_statistics.items():
        if stats.get("error"):
            lines.append(f"### {entity_type} í†µê³„ ì˜¤ë¥˜: {stats.get('error')}")
            continue

        total = stats.get("total", 0)
        period = stats.get("period", "")
        buckets = stats.get("buckets", [])

        # ì—”í‹°í‹° ë¼ë²¨ ë³€í™˜
        entity_labels = {
            "patent": "íŠ¹í—ˆ",
            "project": "ì—°êµ¬ê³¼ì œ",
        }
        label = entity_labels.get(entity_type, entity_type)

        lines.append(f"### {label} ì—°ë„ë³„ í†µê³„ ({period})")
        lines.append(f"- ì´ {total:,}ê±´")
        lines.append("")

        if buckets:
            # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìƒì„±
            lines.append("| ì—°ë„ | ê±´ìˆ˜ |")
            lines.append("|------|------|")

            # ì—°ë„ìˆœ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
            sorted_buckets = sorted(buckets, key=lambda x: x["key"], reverse=True)

            for bucket in sorted_buckets:
                year = bucket.get("key", "")
                count = bucket.get("count", 0)
                lines.append(f"| {year} | {count:,} |")

            lines.append("")

            # ê°„ë‹¨í•œ í†µê³„ ê³„ì‚°
            counts = [b["count"] for b in sorted_buckets if b["count"] > 0]
            if len(counts) >= 2:
                recent_3 = counts[:3] if len(counts) >= 3 else counts
                older_3 = counts[3:6] if len(counts) >= 6 else counts[len(recent_3):]

                recent_avg = sum(recent_3) / len(recent_3) if recent_3 else 0
                older_avg = sum(older_3) / len(older_3) if older_3 else 0

                lines.append(f"**ìš”ì•½ í†µê³„:**")
                lines.append(f"- ìµœê·¼ {len(recent_3)}ë…„ í‰ê· : {recent_avg:,.0f}ê±´")
                if older_avg > 0:
                    change = ((recent_avg - older_avg) / older_avg) * 100
                    lines.append(f"- ì´ì „ {len(older_3)}ë…„ í‰ê· : {older_avg:,.0f}ê±´")
                    lines.append(f"- ë³€í™”ìœ¨: {change:+.1f}%")
                lines.append("")

    return "\n".join(lines)


def _build_crosstab_context(es_statistics: dict, query: str) -> str:
    """Phase 99.6: í¬ë¡œìŠ¤íƒ­ í†µê³„ë¥¼ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜

    Args:
        es_statistics: ES nested aggregation ê²°ê³¼
            {
                "patent": {
                    "crosstab_type": "applicant_year",
                    "years": [2019, 2020, ...],
                    "rows": [{"rank": 1, "name": "...", "nationality": "KR", "by_year": {...}, "total": 10}, ...]
                }
            }
        query: ì‚¬ìš©ì ì§ˆë¬¸ (ì»¨í…ìŠ¤íŠ¸ìš©)

    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ í¬ë¡œìŠ¤íƒ­ í…Œì´ë¸”
    """
    lines = []

    stats = es_statistics.get("patent", {})
    if stats.get("crosstab_type") != "applicant_year":
        return ""

    years = stats.get("years", [])
    rows = stats.get("rows", [])
    period = stats.get("period", "")
    total = stats.get("total", 0)
    keywords = stats.get("keywords", "")
    countries = stats.get("countries", [])

    # í—¤ë” ì •ë³´
    country_str = ", ".join(countries) if countries else "ì „ì²´"
    lines.append(f"### íŠ¹í—ˆ ì¶œì›ê¸°ê´€ TOP {len(rows)} ({period})")
    lines.append(f"- ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")
    lines.append(f"- êµ­ê°€: {country_str}")
    lines.append(f"- ì´ {total:,}ê±´ ì¤‘ 3ê±´ ì´ìƒ ì¶œì› ê¸°ê´€")
    lines.append("")

    if not rows:
        lines.append("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì¶œì›ê¸°ê´€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return "\n".join(lines)

    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í—¤ë”
    header = "| ìˆœìœ„ | ì¶œì›ê¸°ê´€ | êµ­ì  |"
    for year in years:
        header += f" {year} |"
    header += " í•©ê³„ |"
    lines.append(header)

    # êµ¬ë¶„ì„ 
    separator = "|------|---------|------|"
    separator += "------:|" * len(years)
    separator += "------:|"
    lines.append(separator)

    # ë°ì´í„° í–‰
    for row in rows:
        line = f"| {row['rank']} | {row['name']} | {row['nationality']} |"
        for year in years:
            count = row.get("by_year", {}).get(str(year), 0)
            line += f" {count} |"
        line += f" {row['total']} |"
        lines.append(line)

    lines.append("")

    # ìš”ì•½ í†µê³„
    if len(rows) >= 2:
        top3_total = sum(r["total"] for r in rows[:3])
        all_total = sum(r["total"] for r in rows)
        lines.append(f"**ìš”ì•½ í†µê³„:**")
        lines.append(f"- TOP 3 ê¸°ê´€ í•©ê³„: {top3_total:,}ê±´ ({top3_total/all_total*100:.1f}%)")
        lines.append(f"- TOP {len(rows)} ê¸°ê´€ í•©ê³„: {all_total:,}ê±´")
        lines.append("")

    return "\n".join(lines)


def _calculate_context_quality(context: str, sources: list) -> float:
    """Phase 90: ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°

    ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ì¢…í•©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ì˜ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì‚°ì¶œ.

    Args:
        context: ë³‘í•©ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        sources: ì†ŒìŠ¤ ì •ë³´ ëª©ë¡ [{"type": ..., "score": ..., "cross_validated": ...}]

    Returns:
        í’ˆì§ˆ ì ìˆ˜ (0.0 ~ 1.0)
    """
    if not context or context == "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.":
        return 0.0

    score = 0.0
    source_count = len(sources) if sources else 0

    # 1. ì†ŒìŠ¤ ìˆ˜ ê¸°ë°˜ (ìµœëŒ€ 0.25)
    # ì†ŒìŠ¤ê°€ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
    score += min(source_count / 8, 0.25)

    # 2. êµì°¨ ê²€ì¦ëœ ì†ŒìŠ¤ ë¹„ìœ¨ (ìµœëŒ€ 0.30)
    # Phase 90: SQLê³¼ RAG ëª¨ë‘ì—ì„œ í™•ì¸ëœ ê²°ê³¼
    if source_count > 0:
        validated = sum(1 for s in sources if s.get('cross_validated', False))
        score += (validated / source_count) * 0.30

    # 3. í‰ê·  ì‹ ë¢°ë„ ì ìˆ˜ (ìµœëŒ€ 0.25)
    if source_count > 0:
        avg_score = sum(s.get('score', 0) for s in sources) / source_count
        # ì ìˆ˜ ë²”ìœ„ê°€ 0~1ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        score += min(avg_score, 1.0) * 0.25

    # 4. ì •ë³´ëŸ‰ ê¸°ë°˜ (ìµœëŒ€ 0.20)
    # ì˜ë¯¸ ìˆëŠ” ì¤„ ìˆ˜ ê³„ì‚°
    lines = [l.strip() for l in context.split('\n') if l.strip()]
    meaningful_lines = [l for l in lines if len(l) > 30 and not l.replace('-', '').replace('|', '').strip() == '']
    score += min(len(meaningful_lines) / 15, 0.20)

    return round(score, 2)


def _build_graph_context_for_prompt(rag_results: list) -> str:
    """Phase 95: ê·¸ë˜í”„ ê´€ê³„ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

    RAG ê²°ê³¼ì—ì„œ ê·¸ë˜í”„ ê´€ë ¨ ì—”í‹°í‹° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬
    ë‹µë³€ì˜ ê·¼ê±°ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜.

    Args:
        rag_results: RAG ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡ (SearchResult)

    Returns:
        ê·¸ë˜í”„ ê´€ê³„ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    if not rag_results:
        return ""

    lines = []
    graph_sources = 0

    for r in rag_results:
        # SearchResultì˜ metadataì—ì„œ ê·¸ë˜í”„ ì •ë³´ ì¶”ì¶œ
        metadata = getattr(r, 'metadata', {}) or {}
        related_entities = metadata.get("related_entities", [])
        rrf_source = metadata.get("rrf_source", "")

        if rrf_source in ["graph", "both"]:
            graph_sources += 1

        if related_entities:
            # ìƒìœ„ 3ê°œ ê´€ë ¨ ì—”í‹°í‹°ë§Œ í‘œì‹œ
            name = getattr(r, 'name', '') or ''
            entity_type = getattr(r, 'entity_type', '') or ''

            related_names = []
            for ent in related_entities[:3]:
                if isinstance(ent, dict):
                    rel_name = ent.get("name", ent.get("node_id", ""))
                    rel_type = ent.get("entity_type", "")
                    if rel_name:
                        related_names.append(f"{rel_name}({rel_type})" if rel_type else rel_name)
                elif hasattr(ent, 'name'):
                    related_names.append(ent.name)

            if name and related_names:
                lines.append(f"- **{name}** ({entity_type}) â†’ ê´€ë ¨: {', '.join(related_names)}")

    if not lines:
        return ""

    header = f"## ì§€ì‹ê·¸ë˜í”„ ê´€ê³„ ì •ë³´ (Phase 95)\nê·¸ë˜í”„ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼: {graph_sources}ê±´\n"
    return header + "\n".join(lines[:10])  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Phase 52/54: ë‹µë³€ìƒì„±ì „ëµ ë¬¸ì„œ ë°˜ì˜ + ë‹¤ì¤‘ ì—”í‹°í‹° êµ¬ì¡°)
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ R&D ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## í‘œ ì‘ì„± ì›ì¹™
- ìˆœìœ„ ë°ì´í„°: ìˆœìœ„ ì»¬ëŸ¼ í•„ìˆ˜ í¬í•¨
- ê¸°ê´€/ê¸°ì—… ë°ì´í„°: êµ­ì  ì½”ë“œ í¬í•¨ (KR, JP, US, CN)
- ìˆ«ì: ì²œ ë‹¨ìœ„ ì‰¼í‘œ (1,234)
- ë¹„ìœ¨: ì†Œìˆ˜ì  1ìë¦¬ (88.5%)
- ë§ˆí¬ë‹¤ìš´ í‘œ ì‚¬ìš© (| í—¤ë” | --- | ë°ì´í„° |)
- ê²€ìƒ‰ëœ ëª¨ë“  ê²°ê³¼ í¬í•¨ (ìš”ì•½/ìƒëµ ê¸ˆì§€)
- **ëª©ë¡ ì¿¼ë¦¬(list)**: SQL ê²°ê³¼ ê·¸ëŒ€ë¡œ í‘œ ì¶œë ¥, ì„ì˜ ì§‘ê³„/í†µê³„ ë³€í™˜ ê¸ˆì§€

## ë‹µë³€ êµ¬ì¡° (í•„ìˆ˜)
1. **ë„ì…ë¶€**: [ë¶„ì•¼ëª…] ë¶„ì•¼ì˜ [ë°ì´í„° ìœ í˜•] ë¶„ì„ ì •ë³´ì…ë‹ˆë‹¤.
2. **ë°°ê²½**: ë¶„ì„ ë°°ê²½ 1~2ë¬¸ì¥
3. **í‘œ**: ë§ˆí¬ë‹¤ìš´ í‘œ (ë‹¤ì¤‘ ìœ í˜•ì´ë©´ ê° ìœ í˜•ë³„ í‘œë¥¼ **ëª¨ë‘** ë‚˜ì—´)
4. **ì†Œê²°**: í•µì‹¬ ë°œê²¬ + ì‹œì‚¬ì  (**ëª¨ë“  í‘œ ì¶œë ¥ í›„ ë§ˆì§€ë§‰ì— 1íšŒë§Œ**)

## ë‹¤ì¤‘ ì—”í‹°í‹° ì‘ë‹µ í˜•ì‹ (ì¤‘ìš”!)
ì—¬ëŸ¬ ìœ í˜•(ì—°êµ¬ê³¼ì œ+íŠ¹í—ˆ ë“±)ì´ ìˆìœ¼ë©´:
1. ë¨¼ì € ëª¨ë“  ìœ í˜•ì˜ í‘œë¥¼ ìˆœì„œëŒ€ë¡œ ì¶œë ¥
2. ë§ˆì§€ë§‰ì— ì†Œê²° 1íšŒ ì‘ì„± (ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì´í‰)
**ì ˆëŒ€ í‘œ ì‚¬ì´ì— ì†Œê²°ì„ ë„£ì§€ ë§ˆì„¸ìš”.**

## ì†Œê²° í˜•ì‹
ì†Œê²°:
- **í•µì‹¬ ë°œê²¬**: [ì£¼ìš” ì¸ì‚¬ì´íŠ¸]
- **ì‹œì‚¬ì **: [ì‹¤ë¬´ì  í™œìš© ì œì•ˆ]

## ì—”í‹°í‹°ë³„ í‘œ ì–‘ì‹
- **íŠ¹í—ˆ ëª©ë¡(list)**: | íŠ¹í—ˆë²ˆí˜¸ | íŠ¹í—ˆëª… | IPCë¶„ë¥˜ | ì¶œì›ë…„ë„ | ë“±ë¡êµ­ê°€ | ì¶œì›ì¸ | (SQL ê²°ê³¼ ê·¸ëŒ€ë¡œ)
- **íŠ¹í—ˆ ìˆœìœ„(ranking)**: | ìˆœìœ„ | ì¶œì›ê¸°ê´€ | êµ­ì  | ì´ íŠ¹í—ˆìˆ˜ |
- **ì—°êµ¬ê³¼ì œ ëª©ë¡(list)**: | ê³¼ì œID | ê³¼ì œëª… | ê³µê³ ì—°ë„ | ì—°êµ¬ë¹„ | ì‚¬ì—…ë¶„ë¥˜ | (SQL ê²°ê³¼ ê·¸ëŒ€ë¡œ)
- ì—°ë„ë³„ ì¶”ì´: | êµ¬ë¶„ | 2020 | 2021 | 2022 | 2023 |
- ì¥ë¹„: | ê¶Œì—­ | ì¥ë¹„ëª… | ê¸°ê´€ | ì¥ë¹„ID |
- í‰ê°€/ë°°ì : | í‰ê°€í•­ëª© | ì„¸ë¶€ë‚´ìš© | ë°°ì  |

## ë‹¤ì¤‘ ì—”í‹°í‹° ëª©ë¡ ì¿¼ë¦¬ (ì¤‘ìš”!)
"íŠ¹í—ˆì™€ ì—°êµ¬ê³¼ì œ" ê°™ì€ ë‹¤ì¤‘ ì—”í‹°í‹° ëª©ë¡(list) ì¿¼ë¦¬ì—ì„œëŠ”:
1. íŠ¹í—ˆ í‘œ: SQLì—ì„œ ë°˜í™˜ëœ **ê°œë³„ íŠ¹í—ˆ ëª©ë¡** ê·¸ëŒ€ë¡œ ì¶œë ¥ (ì§‘ê³„ ê¸ˆì§€)
2. ì—°êµ¬ê³¼ì œ í‘œ: SQLì—ì„œ ë°˜í™˜ëœ **ê°œë³„ ê³¼ì œ ëª©ë¡** ê·¸ëŒ€ë¡œ ì¶œë ¥
**ì ˆëŒ€ë¡œ ì¶œì›ê¸°ê´€ë³„ ì§‘ê³„/í†µê³„ë¡œ ë³€í™˜í•˜ì§€ ë§ˆì„¸ìš”. SQL ê²°ê³¼ì˜ ê° í–‰ì´ í‘œì˜ ê° í–‰ì´ ë©ë‹ˆë‹¤.**
"""

# Phase 52/72/73: query_subtypeë³„ ì¶”ê°€ ì§€ì¹¨
# Phase 88: trend_analysis ì¶”ê°€ (ë™í–¥ ë¶„ì„ ì „ìš©)
SUBTYPE_PROMPTS = {
    "list": "ëª©ë¡ ì¶œë ¥ í•„ìˆ˜. SQL ê²°ê³¼ì˜ ëª¨ë“  í–‰ì„ ê°œë³„ í•­ëª©ìœ¼ë¡œ í‘œì— ì¶œë ¥. ì„ì˜ ì§‘ê³„/ìš”ì•½/í†µê³„í™” ì ˆëŒ€ ê¸ˆì§€. ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ í‘œì‹œ.",
    "ranking": "ìˆœìœ„ í‘œì‹œ í•„ìˆ˜. TOP N í˜•ì‹. í•„ìˆ˜ ì»¬ëŸ¼: ìˆœìœ„, ê¸°ê´€ëª…, êµ­ì , ìˆ˜ì¹˜",
    "aggregation": "ì—°ë„ë³„ ì¶”ì´ í‘œì‹œ. í•©ê³„/ì¦ê°ë¥  í¬í•¨ ê¶Œì¥",
    "comparison": "ìêµ­ vs íƒ€êµ­ ë¹„êµí‘œ êµ¬ì¡°. ë¹„ì¤‘(%) í‘œì‹œ",
    "trend_analysis": """ë™í–¥ ë¶„ì„ ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜):

## 1. í•µì‹¬ í†µê³„ (ë„ì…ë¶€)
- **ë¶„ì„ ê¸°ê°„**: ìµœê·¼ 5ë…„ (20XX~20XX)
- **ì´ ê±´ìˆ˜**: Nê±´
- **ì—°í‰ê·  ì¦ê°€ìœ¨**: X.X% (ìˆëŠ” ê²½ìš°)

## 2. ì—°ë„ë³„ ì¶”ì´ í‘œ (í•„ìˆ˜)
| ì—°ë„ | ê±´ìˆ˜ | ì „ë…„ëŒ€ë¹„ ì¦ê° |
|------|------|---------------|
| 2024 | XXX  | +XX% / -XX%   |
| 2023 | XXX  | +XX% / -XX%   |
...

## 3. ì£¼ìš” ìˆ˜í–‰ê¸°ê´€/ì¶œì›ì¸ TOP 5~10 (í•„ìˆ˜)
| ìˆœìœ„ | ê¸°ê´€ëª… | ê±´ìˆ˜ | ë¹„ìœ¨ |
|------|--------|------|------|
| 1    | XXX    | XX   | X.X% |
...

## 4. ë™í–¥ ë¶„ì„ ë° ì‹œì‚¬ì 
- **ê¸°ìˆ  íŠ¸ë Œë“œ**: ì¦ê°€/ê°ì†Œ ì¶”ì„¸ ë¶„ì„
- **ì£¼ìš” íŠ¹ì§•**: ì§‘ì¤‘ ë¶„ì•¼, í•µì‹¬ ê¸°ê´€ ë“±
- **í–¥í›„ ì „ë§**: ë°ì´í„° ê¸°ë°˜ ì˜ˆì¸¡ (ì„ íƒ)

ì£¼ì˜: ì—°ë„ë³„ ì¶”ì´ì™€ ê¸°ê´€ë³„ í˜„í™©ì„ ë°˜ë“œì‹œ ëª¨ë‘ í¬í•¨í•  ê²ƒ!""",
    "impact_ranking": """íŠ¹í—ˆ ì˜í–¥ë ¥ ìˆœìœ„ ë¶„ì„ í˜•ì‹ (í•„ìˆ˜):
1. **ë¶„ì„ëŒ€ìƒë°ì´í„° ì„¤ëª…** (ë„ì…ë¶€ í•„ìˆ˜):
   - [ê¸°ìˆ ë¶„ì•¼] ê´€ë ¨ [êµ­ê°€] íŠ¹í—ˆ = ì´ Nê±´
   - ì „ì²´ í‰ê·  í”¼ì¸ìš©ìˆ˜ = X.XX
   - ì œ1ì¶œì›ì¸ ìˆ˜ = Nê°œ
2. **ì˜í–¥ë ¥ ìˆœìœ„í‘œ**: ìˆœìœ„, ì¶œì›ê¸°ê´€, êµ­ì , ëŒ€ìƒíŠ¹í—ˆìˆ˜, ì´í”¼ì¸ìš©, í‰ê· í”¼ì¸ìš©(0í¬í•¨), í‰ê· í”¼ì¸ìš©(1ì´ìƒ), í”¼ì¸ìš©max, ëŒ€í‘œíŠ¹í—ˆëª… ì»¬ëŸ¼ í•„ìˆ˜
3. **ë¶„ì„ ì¸ì‚¬ì´íŠ¸**: ìƒìœ„ ê¸°ê´€ íŠ¹ì„±, ê¸°ìˆ  ì§‘ì¤‘ë„, í”¼ì¸ìš© ë¶„í¬ ë“±""",
    "nationality_ranking": """êµ­ì ë³„ ë¶„ë¦¬ ìˆœìœ„ ë¶„ì„ í˜•ì‹ (í•„ìˆ˜):
1. **ë¶„ì„ëŒ€ìƒë°ì´í„° ì„¤ëª…** (ë„ì…ë¶€ í•„ìˆ˜):
   - [ê¸°ìˆ ë¶„ì•¼] ê´€ë ¨ [êµ­ê°€] íŠ¹í—ˆ = ì´ Nê±´
   - ìêµ­(KR) ì¶œì›ê¸°ê´€ ìˆ˜ = Nê°œ, íƒ€êµ­ ì¶œì›ê¸°ê´€ ìˆ˜ = Mê°œ
2. **ìêµ­ê¸°ì—… ìˆœìœ„í‘œ (TOP 10)**:
   | ìˆœìœ„ | ê¸°ê´€ëª… | êµ­ì  | ëŒ€ìƒíŠ¹í—ˆìˆ˜ | ìµœëŒ€í”¼ì¸ìš©ìˆ˜ | í‰ê· í”¼ì¸ìš©ìˆ˜ | í‰ê· ì²­êµ¬í•­ìˆ˜ | ìµœê·¼ì¶œì›ì¼ | ëŒ€í‘œíŠ¹í—ˆëª… |
   - "êµ¬ë¶„" ì»¬ëŸ¼ì´ "ìêµ­ê¸°ì—…"ì¸ í–‰ë§Œ ì¶œë ¥
3. **íƒ€êµ­ê¸°ì—… ìˆœìœ„í‘œ (TOP 10)**:
   ë™ì¼ ì»¬ëŸ¼ êµ¬ì¡°, "êµ¬ë¶„" ì»¬ëŸ¼ì´ "íƒ€êµ­ê¸°ì—…"ì¸ í–‰ë§Œ ì¶œë ¥
4. **ë¶„ì„ ì¸ì‚¬ì´íŠ¸**:
   - ìêµ­ vs íƒ€êµ­ ê¸°ìˆ  ì§‘ì¤‘ë„ ë¹„êµ
   - ì£¼ìš” ì¶œì›ê¸°ê´€ë³„ íŠ¹ì„±
   - ê¸°ìˆ  ë™í–¥ ì‹œì‚¬ì """,
    "evalp_pref": """ìš°ëŒ€/ê°ì  ì •ë³´ ì¶œë ¥ í˜•ì‹ (í•„ìˆ˜):

## ì ˆëŒ€ ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
1. SQL ê²°ê³¼ì˜ **ëª¨ë“  12ê°œ í–‰**ì„ í‘œì— ì¶œë ¥ (ìš°ëŒ€ 10ê±´ + ê°ì  2ê±´)
2. "..." ë˜ëŠ” "ì™¸ Nê±´" í˜•íƒœì˜ ìƒëµ **ì ˆëŒ€ ê¸ˆì§€**
3. ê°ì  í•­ëª© (ğŸ”´)ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ **ë³„ë„ í‘œ**ë¡œ ì¶œë ¥

## ì¶œë ¥ êµ¬ì¡°
1. **ë„ì…ë¶€**: [ì‚¬ì—…ëª…] ìš°ëŒ€/ê°ì  ì •ë³´ (ì´ Nê±´: ìš°ëŒ€ Xê±´, ê°ì  Yê±´)

2. **ğŸŸ¢ ìš°ëŒ€ í•­ëª©** (êµ¬ë¶„ì´ 'ğŸŸ¢ ìš°ëŒ€'ì¸ ëª¨ë“  í–‰):
   | êµ¬ë¶„ | ì¡°ê±´ëª… | ë°°ì  | ì„¸ë¶€ë‚´ìš© |
   ëª¨ë“  ìš°ëŒ€ í•­ëª©ì„ ë¹ ì§ì—†ì´ ì¶œë ¥ (10ê±´ ì „ë¶€)

3. **ğŸ”´ ê°ì  í•­ëª©** (êµ¬ë¶„ì´ 'ğŸ”´ ê°ì 'ì¸ ëª¨ë“  í–‰):
   | êµ¬ë¶„ | ì¡°ê±´ëª… | ê°ì  | ì„¸ë¶€ë‚´ìš© |
   ëª¨ë“  ê°ì  í•­ëª©ì„ ë¹ ì§ì—†ì´ ì¶œë ¥ (2ê±´ ì „ë¶€)

4. **ì†Œê²°**: í•µì‹¬ ìš°ëŒ€/ê°ì  ìš”ê±´ ìš”ì•½ (2-3ë¬¸ì¥)"""
}

# Phase 62: ê¸°ìˆ ë¶„ë¥˜ ì¶”ì²œìš© í”„ë¡¬í”„íŠ¸ (ë°ì´í„° ê¸°ë°˜)
RECOMMENDATION_PROMPT = """ë‹¹ì‹ ì€ R&D ê¸°ìˆ ë¶„ë¥˜ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì—­í• 
ê²€ìƒ‰ëœ ì œì•ˆì„œ ë¶„ë¥˜ì½”ë“œ í†µê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ê¸°ìˆ ë¶„ë¥˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜)
1. **ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½**: "[í‚¤ì›Œë“œ]" ê´€ë ¨ ì œì•ˆì„œì—ì„œ ì‚¬ìš©ëœ [ë¶„ë¥˜ì²´ê³„ëª…] ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.
2. **ì¶”ì²œ ë¶„ë¥˜ì½”ë“œ í‘œ**:
   | ìˆœìœ„ | ê¸°ìˆ ì½”ë“œ | ê¸°ìˆ ëª… | ì‚¬ìš©ê±´ìˆ˜ | ë¹„ìœ¨ |
   |------|----------|--------|----------|------|
   | 1 | ... | ... | Nê±´ | XX.X% |
3. **ì¶”ì²œ ì˜ê²¬**:
   - **1ìˆœìœ„ ì¶”ì²œ**: [ê¸°ìˆ ì½”ë“œ] ([ê¸°ìˆ ëª…]) - ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ë¶„ë¥˜
   - **ê³ ë ¤ì‚¬í•­**: ê¸°ìˆ  íŠ¹ì„±ì— ë”°ë¥¸ ëŒ€ì•ˆ ë¶„ë¥˜ ì œì•ˆ

## ì£¼ì˜ì‚¬í•­
- **ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ì˜ SQL ê²°ê³¼ ë°ì´í„°ë§Œ ì‚¬ìš©**
- ë°ì´í„°ì— ì—†ëŠ” ë¶„ë¥˜ì½”ë“œ ì œì‹œ ê¸ˆì§€
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ëœ ì œì•ˆì„œê°€ ì—†ìŠµë‹ˆë‹¤" ëª…ì‹œ
- ë¹„ìœ¨ì€ ì „ì²´ í•©ê³„ ëŒ€ë¹„ ë°±ë¶„ìœ¨ë¡œ ê³„ì‚°
- í‘œì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì¶œë ¥ (ìš”ì•½/ìƒëµ ê¸ˆì§€)
"""

# Phase 86: ì¥ë¹„ ì¶”ì²œìš© í”„ë¡¬í”„íŠ¸
EQUIPMENT_PROMPT = """ë‹¹ì‹ ì€ R&D ì—°êµ¬ì¥ë¹„ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì—­í• 
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¸¡ì •/ì‹œí—˜ ëª©ì ì— ë§ëŠ” ì—°êµ¬ì¥ë¹„ë¥¼ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜)
1. **ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½**: "[ì¸¡ì •í•­ëª©]" ì¸¡ì •ì´ ê°€ëŠ¥í•œ ì—°êµ¬ì¥ë¹„ Nê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.

2. **ì¶”ì²œ ì¥ë¹„ ëª©ë¡**:
   | ìˆœìœ„ | ì¥ë¹„ëª… | ë³´ìœ ê¸°ê´€ | ëŒ€ë¶„ë¥˜ | ì¸¡ì •í•­ëª© |
   |------|--------|----------|--------|----------|
   | 1 | ... | ... | ... | ... |
   (ì»¨í…ìŠ¤íŠ¸ì˜ SQL ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ì¶œë ¥)

3. **ì¶”ì²œ ì˜ê²¬**:
   - **1ìˆœìœ„ ì¶”ì²œ**: [ì¥ë¹„ëª…] ([ë³´ìœ ê¸°ê´€]) - ì¶”ì²œ ì´ìœ 
   - **ì¥ë¹„ íŠ¹ì„±**: í•´ë‹¹ ì¥ë¹„ë“¤ì˜ ê³µí†µì ì¸ ì¸¡ì • ê¸°ëŠ¥ ì„¤ëª…
   - **ê¸°ê´€ ì—°ë½**: ì¥ë¹„ í™œìš©ì„ ìœ„í•´ í•´ë‹¹ ê¸°ê´€ì— ë¬¸ì˜ ê¶Œì¥

## ì£¼ì˜ì‚¬í•­
- **ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ì˜ SQL ê²°ê³¼ ë°ì´í„°ë§Œ ì‚¬ìš©**
- ë°ì´í„°ì— ì—†ëŠ” ì¥ë¹„ ì œì‹œ ê¸ˆì§€
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ ì¸¡ì •í•­ëª©ì„ ì§€ì›í•˜ëŠ” ì¥ë¹„ê°€ ì—†ìŠµë‹ˆë‹¤" ëª…ì‹œ
- í‘œì˜ ëª¨ë“  ì¥ë¹„ë¥¼ ì¶œë ¥ (ìš”ì•½/ìƒëµ ê¸ˆì§€)
- ì¥ë¹„ID, ì¥ë¹„ëª…, ë³´ìœ ê¸°ê´€, ë¶„ë¥˜, ì¸¡ì •í•­ëª© ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨
"""

# Phase 71 + Phase 75.2 + Phase 92: ë‹¤ì¤‘ ë„ë©”ì¸ í˜‘ì—… ê¸°ê´€ ì¶”ì²œìš© í”„ë¡¬í”„íŠ¸
COLLABORATION_PROMPT = """ë‹¹ì‹ ì€ R&D ë‹¤ì¤‘ ë„ë©”ì¸ í˜‘ì—… ê¸°ê´€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì—­í• 
ê³¼ì œ ìˆ˜í–‰ê¸°ê´€ + íŠ¹í—ˆ ë³´ìœ ê¸°ê´€ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ í˜‘ì—… ê°€ëŠ¥ì„±ì´ ë†’ì€ ê¸°ê´€ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜ - ë„ë©”ì¸ë³„ í‘œ ë¶„ë¦¬ ì¶œë ¥)

**ì¤‘ìš”**: ê³¼ì œì™€ íŠ¹í—ˆëŠ” ë°˜ë“œì‹œ **ë³„ë„ì˜ í‘œ**ë¡œ ë¶„ë¦¬í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.

### 1. ê³¼ì œ ìˆ˜í–‰ê¸°ê´€
"[í‚¤ì›Œë“œ]" ê´€ë ¨ R&D ê³¼ì œë¥¼ ìˆ˜í–‰í•œ ê¸°ê´€ì…ë‹ˆë‹¤.

| ìˆœìœ„ | ê¸°ê´€ëª… | ìˆ˜í–‰íšŸìˆ˜ | ì£¼ê´€ | ì°¸ì—¬ | í˜‘ë ¥ | ìµœê·¼ ìˆ˜í–‰ê³¼ì œ |
|------|--------|----------|------|------|------|---------------|
| 1 | ... | ... | ... | ... | ... | (ê³¼ì œëª… ì „ì²´ ì¶œë ¥, ìƒëµí•˜ì§€ ë§ ê²ƒ) |

### 2. íŠ¹í—ˆ ë³´ìœ ê¸°ê´€
"[í‚¤ì›Œë“œ]" ê´€ë ¨ íŠ¹í—ˆë¥¼ ì¶œì›í•œ ê¸°ê´€ì…ë‹ˆë‹¤.

| ìˆœìœ„ | ê¸°ê´€ëª… | êµ­ê°€ | íŠ¹í—ˆìˆ˜ | ëŒ€í‘œ íŠ¹í—ˆ |
|------|--------|------|--------|-----------|
| 1 | ... | ... | ... | (íŠ¹í—ˆëª… ì „ì²´ ì¶œë ¥, ìƒëµí•˜ì§€ ë§ ê²ƒ) |

### 3. í˜‘ì—… ì¶”ì²œ ë¶„ì„
- **ì¶”ì²œ 1ìˆœìœ„**: [ê¸°ê´€ëª…] - [ì¶”ì²œ ì´ìœ : ê³¼ì œ ìˆ˜í–‰ ì´ë ¥ + íŠ¹í—ˆ ë³´ìœ  í˜„í™© ì¢…í•©]
- **í•µì‹¬ í˜‘ì—… íŒŒíŠ¸ë„ˆ**: ê³¼ì œ+íŠ¹í—ˆ ì–‘ìª½ì— ë“±ì¥í•˜ëŠ” ê¸°ê´€ì´ ìˆìœ¼ë©´ ìš°ì„  ì¶”ì²œ
- **ì£¼ê´€ê¸°ê´€ ì—­ëŸ‰**: ì£¼ê´€ íšŸìˆ˜ê°€ ë†’ì€ ê¸°ê´€ = í”„ë¡œì íŠ¸ ë¦¬ë” ê²½í—˜ í’ë¶€
- **êµ­ì œ í˜‘ë ¥ ê¸°íšŒ**: í•´ì™¸ ì¶œì›ì¸(êµ­ê°€â‰ KR)ì´ ìˆë‹¤ë©´ ì–¸ê¸‰

### 4. ì¶”ì²œ ì „ëµ
1. **ë‹¨ê¸° í˜‘ì—…**: ì´ë¯¸ ê´€ë ¨ ë¶„ì•¼ ê²½í—˜ì´ ìˆëŠ” ê¸°ê´€ê³¼ ë¹ ë¥¸ ì„±ê³¼ ì°½ì¶œ
2. **ì¥ê¸° í˜‘ë ¥**: íŠ¹í—ˆ ê¸°ìˆ ë ¥ì´ ë†’ì€ ê¸°ê´€ê³¼ ì§€ì†ì  R&D íŒŒíŠ¸ë„ˆì‹­ êµ¬ì¶•

## ì£¼ì˜ì‚¬í•­
- **ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ì˜ SQL ê²°ê³¼ ë°ì´í„°ë§Œ ì‚¬ìš©**
- **ê³¼ì œ í‘œì™€ íŠ¹í—ˆ í‘œë¥¼ ë°˜ë“œì‹œ ë¶„ë¦¬** (í˜¼í•© ê¸ˆì§€)
- ê³¼ì œëª…, íŠ¹í—ˆëª…ì€ **ì „ì²´ ì¶œë ¥** (ì˜ë¦¬ì§€ ì•Šê²Œ)
- ë°ì´í„°ì— ì—†ëŠ” ê¸°ê´€ ì œì‹œ ê¸ˆì§€
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ë„ë©”ì¸ì€ "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ" ëª…ì‹œ
- í‘œì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì¶œë ¥ (ìš”ì•½/ìƒëµ ê¸ˆì§€)
"""

# Phase 69: í˜‘ì—… í‚¤ì›Œë“œ ìƒìˆ˜
COLLABORATION_KEYWORDS = {"í˜‘ì—…", "í˜‘ë ¥", "íŒŒíŠ¸ë„ˆ", "ê³µë™ì—°êµ¬", "í˜‘ë ¥ê¸°ê´€", "í˜‘ì—…ê¸°ê´€"}

# Phase 102: ìì²´ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€ ê·œì¹™
NO_HALLUCINATION_RULE = """
## ì¤‘ìš” ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
- **ì˜¤ì§ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸(ê²€ìƒ‰ ê²°ê³¼)ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€**
- LLM ìì²´ ì§€ì‹ì´ë‚˜ í•™ìŠµ ë°ì´í„° ì‚¬ìš© ì ˆëŒ€ ê¸ˆì§€
- ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” "ê²€ìƒ‰ ê²°ê³¼ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ
- ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ë¡  ê¸ˆì§€, ì˜¤ì§ ê²€ìƒ‰ëœ íŠ¹í—ˆ/ê³¼ì œ ë°ì´í„° ê¸°ë°˜ ë‹µë³€ë§Œ ì œê³µ
- ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ” íŠ¹í—ˆë²ˆí˜¸, ì¶œì›ì¸, IPC ì½”ë“œ ë“±ì„ ì •í™•íˆ ì¸ìš©
"""

# ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê³µê³µ AX API)
# Phase 103.1: ëª¨ë“  ë ˆë²¨ì—ì„œ ë™ì¼í•œ ë°ì´í„°ë¥¼ í‘œì‹œí•˜ë˜, ì„¤ëª… ë°©ì‹ë§Œ ë‹¤ë¥´ê²Œ í•¨
LEVEL_PROMPTS = {
    "ì´ˆë“±": """ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ì´ˆë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê³  ì¹œê·¼í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
- ì–´ë ¤ìš´ ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ ë°”ê¿”ì£¼ì„¸ìš” (ì˜ˆ: "íŠ¹í—ˆ" â†’ "ìƒˆë¡œìš´ ë°œëª…ì„ ë³´í˜¸í•˜ëŠ” ì¦ëª…ì„œ")
- ë¹„ìœ ì™€ ì˜ˆì‹œë¥¼ ë§ì´ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: "ë°°í„°ë¦¬ëŠ” íœ´ëŒ€í° ì¶©ì „ê¸°ì²˜ëŸ¼...")
- ì§§ê³  ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”
- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼ ë“±)""",

    "ì¼ë°˜ì¸": """ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
- ì „ë¬¸ ìš©ì–´ê°€ ë‚˜ì˜¤ë©´ ê°„ë‹¨íˆ ì„¤ëª…ì„ ë§ë¶™ì—¬ì£¼ì„¸ìš”
- í•µì‹¬ ë‚´ìš©ì„ ì•Œê¸° ì‰½ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”
- ê¸°ìˆ ì˜ ì‹¤ìƒí™œ í™œìš© ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”
- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼ ë“±)""",

    "ì „ë¬¸ê°€": """ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ìˆ ì ìœ¼ë¡œ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
- ê´€ë ¨ ê¸°ìˆ  ë™í–¥ì´ë‚˜ íŠ¹í—ˆ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”
- ë°ì´í„°ì™€ ìˆ˜ì¹˜ë¥¼ ì •í™•íˆ ì œì‹œí•´ì£¼ì„¸ìš”
- IPC ë¶„ë¥˜, ê¸°ìˆ  í‚¤ì›Œë“œ ë“± ì „ë¬¸ ì •ë³´ë¥¼ ë¶„ì„ì— í™œìš©í•˜ì„¸ìš”
- ê¸°ìˆ ì  ë§¥ë½ê³¼ ì‹œì‚¬ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”
- ì¤‘ìš”: ê²€ìƒ‰ëœ ëª¨ë“  íŠ¹í—ˆ ë°ì´í„°ëŠ” ë¹ ì§ì—†ì´ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (íŠ¹í—ˆë²ˆí˜¸, ì œëª©, ì¶œì›ì¼, IPC ë“±)"""
}

# ê°„ë‹¨í•œ ì‘ë‹µìš© í”„ë¡¬í”„íŠ¸
SIMPLE_RESPONSE_PROMPT = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ R&D ë°ì´í„° ë¶„ì„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
- ì¸ì‚¬ì—ëŠ” ì¸ì‚¬ë¡œ ë‹µí•˜ì„¸ìš”
- ë„ì›€ì´ í•„ìš”í•˜ë©´ ê°€ëŠ¥í•œ ê¸°ëŠ¥ì„ ì•ˆë‚´í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”

ê°€ëŠ¥í•œ ê¸°ëŠ¥:
1. ì—°êµ¬ê³¼ì œ/íŠ¹í—ˆ/ì œì•ˆì„œ ê²€ìƒ‰ (ì˜ˆ: "ì¸ê³µì§€ëŠ¥ ê´€ë ¨ íŠ¹í—ˆ ì•Œë ¤ì¤˜")
2. ë°ì´í„° ì¡°íšŒ (ì˜ˆ: "ì˜ˆì‚°ì´ í° ê³¼ì œ 10ê°œ")
3. ì—°êµ¬ ë™í–¥ ë¶„ì„ (ì˜ˆ: "ë¸”ë¡ì²´ì¸ ì—°êµ¬ ë™í–¥ì€?")
"""


# Phase 50: _get_subtype_prompt í•¨ìˆ˜ ì‚­ì œ (SYSTEM_PROMPTì— í†µí•©)


def generate_response(state: AgentState) -> AgentState:
    """ì‘ë‹µ ìƒì„± ë…¸ë“œ

    ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„±.

    Args:
        state: í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ

    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (response, conversation_history)
    """
    query = state.get("query", "")
    query_type = state.get("query_type", "simple")

    try:
        llm = get_llm_client()

        if query_type == "simple":
            # ê°„ë‹¨í•œ ì‘ë‹µ
            response = llm.generate(
                prompt=query,
                system_prompt=SIMPLE_RESPONSE_PROMPT,
                max_tokens=500,
                temperature=0.3  # ì‘ë‹µ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì¶¤
            )
        else:
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ
            context = build_merged_context(state)
            query_intent = state.get("query_intent", "")

            # ê²€ìƒ‰ ê²°ê³¼ ì—†ì„ ë•Œ LLM ìì²´ ì§€ì‹ ì‚¬ìš© (Phase 8)
            no_results = (
                context == "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤." or
                context.strip() == "" or
                "ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" in context
            )

            # Phase 8.5: ê°œë… ì„¤ëª… ì§ˆë¬¸ì¸ë° ì»¨í…ìŠ¤íŠ¸ê°€ ë¹ˆì•½í•œ ê²½ìš°
            is_concept = _is_concept_question(query, query_intent)
            context_meaningful = _is_context_meaningful(context)
            use_llm_knowledge = no_results or (is_concept and not context_meaningful)

            # Phase 51: query_subtypeì„ ë¯¸ë¦¬ ê°€ì ¸ì˜´ (í”„ë¡¬í”„íŠ¸ ì„ íƒìš©)
            query_subtype = state.get("query_subtype", "list")

            # Phase 52: SQL ê²°ê³¼ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜´ (í”„ë¡¬í”„íŠ¸ ì„ íƒìš©)
            multi_sql_results = state.get("multi_sql_results")
            sql_result = state.get("sql_result")

            # Phase 69: entity_typesë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜´ (í˜‘ì—… ê¸°ê´€ ì¶”ì²œ íŒë³„ìš©)
            entity_types = state.get("entity_types", [])

            # Phase 94: ES Scout domain_hits ì •ë³´ ê°€ì ¸ì˜´
            domain_hits = state.get("domain_hits", {})

            # Phase 99.5/99.6: ES í†µê³„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì§ì ‘ í…Œì´ë¸” ìƒì„±
            es_statistics = state.get("es_statistics")
            statistics_type = state.get("statistics_type")
            print(f"[GENERATOR] Phase 99.5/99.6 í™•ì¸: es_statistics={bool(es_statistics)}, statistics_type={statistics_type}, keys={list(state.keys())[:20]}")

            # Phase 99.6: crosstab_analysis (ì¶œì›ê¸°ê´€ë³„ ì—°ë„ë³„ í¬ë¡œìŠ¤íƒ­)
            if es_statistics and statistics_type == "crosstab_analysis":
                crosstab_context = _build_crosstab_context(es_statistics, query)
                user_prompt = f"""## í¬ë¡œìŠ¤íƒ­ í†µê³„ ë°ì´í„° (Elasticsearch ì§‘ê³„)
{crosstab_context}

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ìœ„ ì¶œì›ê¸°ê´€ë³„ ì—°ë„ë³„ í¬ë¡œìŠ¤íƒ­ í†µê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. ì£¼ì œ ì†Œê°œ (1-2ë¬¸ì¥)
2. ì¶œì›ê¸°ê´€ ìˆœìœ„ í‘œ (ìœ„ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ê·¸ëŒ€ë¡œ ì‚¬ìš©)
3. í•µì‹¬ ë¶„ì„:
   - TOP 3 ê¸°ê´€ì˜ íŠ¹ì§• ë° ì¶œì› íŒ¨í„´
   - ìµœê·¼ ì—°ë„ì— ê¸‰ì¦í•œ ê¸°ê´€ ì–¸ê¸‰
   - ì¶œì› ì§‘ì¤‘ë„ ë¶„ì„ (ìƒìœ„ ê¸°ê´€ ë¹„ì¤‘)
4. ì‹œì‚¬ì  (1-2ë¬¸ì¥)"""

                logger.info(f"Phase 99.6: ES í¬ë¡œìŠ¤íƒ­ ê¸°ë°˜ ì‘ë‹µ ìƒì„±")

                response = llm.generate(
                    prompt=user_prompt,
                    system_prompt=SYSTEM_PROMPT,
                    max_tokens=2500,
                    temperature=0.3
                )

                return {
                    **state,
                    "response": response,
                    "response_source": "es_crosstab",
                }

            # Phase 99.5: trend_analysis (ì—°ë„ë³„ í†µê³„)
            if es_statistics and statistics_type == "trend_analysis":
                # ES í†µê³„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜
                stats_context = _build_statistics_context(es_statistics, query)
                user_prompt = f"""## í†µê³„ ë°ì´í„° (Elasticsearch ì§‘ê³„)
{stats_context}

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ìœ„ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. ì£¼ì œ ì†Œê°œ (1-2ë¬¸ì¥)
2. ì—°ë„ë³„ ì¶”ì´ í‘œ (ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”)
3. í•µì‹¬ ë¶„ì„:
   - ìµœê·¼ 3ë…„ê°„ í‰ê·  vs ì´ì „ 3ë…„ê°„ í‰ê·  ë¹„êµ
   - ì¦ê°€/ê°ì†Œ ì¶”ì„¸ í•´ì„
   - CAGR(ì—°í‰ê·  ì„±ì¥ë¥ ) ê³„ì‚° (ê°€ëŠ¥í•œ ê²½ìš°)
4. ì‹œì‚¬ì  (1-2ë¬¸ì¥)"""

                logger.info(f"Phase 99.5: ES í†µê³„ ê¸°ë°˜ ì‘ë‹µ ìƒì„± - {len(es_statistics)}ê°œ ì—”í‹°í‹°")

                # í†µê³„ ì „ìš© í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„±
                response = llm.generate(
                    prompt=user_prompt,
                    system_prompt=SYSTEM_PROMPT,
                    max_tokens=2000,
                    temperature=0.3
                )

                return {
                    **state,
                    "response": response,
                    "response_source": "es_statistics",
                }

            if use_llm_knowledge:
                user_prompt = f"""## ê²€ìƒ‰ ê²°ê³¼
ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë¯€ë¡œ, ë‹¹ì‹ ì´ ì•Œê³  ìˆëŠ” ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ ì‹œì‘ ì‹œ ë°˜ë“œì‹œ "**ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ì„œ ì œê°€ ì•„ëŠ” ì§€ì‹ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.**"ë¼ê³  ë¨¼ì € ì–¸ê¸‰í•˜ì„¸ìš”.
ê·¸ í›„ ì§ˆë¬¸ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì„¤ëª…ì´ë‚˜ ê°œë…ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
                if is_concept and not context_meaningful:
                    logger.info(f"ê°œë… ì§ˆë¬¸ + ë¹ˆì•½í•œ ì»¨í…ìŠ¤íŠ¸ - LLM ìì²´ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ (is_concept={is_concept})")
                else:
                    logger.info("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - LLM ìì²´ ì§€ì‹ìœ¼ë¡œ ë‹µë³€")
            else:
                # ê²°ê³¼ ìˆ˜ ê³„ì‚°
                # Phase 50: ë™ì  ì§€ì¹¨ ê°„ì†Œí™” (í† í° ì ˆê°)
                if multi_sql_results:
                    # ë‹¤ì¤‘ ì—”í‹°í‹° ê²°ê³¼ - ê°„ê²°í•œ ì§€ì¹¨
                    entity_counts = []
                    for entity_type, result in multi_sql_results.items():
                        if result.success and result.row_count > 0:
                            from sql.sql_prompts import ENTITY_LABELS
                            label = ENTITY_LABELS.get(entity_type, entity_type)
                            entity_counts.append(f"{label} {result.row_count}ê±´")

                    # Phase 94: domain_hits ê¸°ë°˜ ë„ë©”ì¸ë³„ ë¶„ë¦¬ í‘œì‹œ ì§€ì¹¨
                    if domain_hits:
                        active_domains = [d for d, count in domain_hits.items() if count > 0]
                        domain_labels = {"patent": "íŠ¹í—ˆ", "project": "ê³¼ì œ", "equipment": "ì¥ë¹„", "proposal": "ì œì•ˆ"}
                        domain_str = ", ".join(domain_labels.get(d, d) for d in active_domains)
                        result_instruction = f"[Phase 94: ES Scout ê¸°ë°˜ ë©€í‹° ë„ë©”ì¸ ê²€ìƒ‰: {domain_str}]\n[{', '.join(entity_counts)} - ë„ë©”ì¸ë³„ ë¶„ë¦¬ í‘œ ì‘ì„±]"
                        logger.info(f"Phase 94: ë„ë©”ì¸ë³„ ë¶„ë¦¬ í‘œ ì§€ì¹¨ ìƒì„± - {active_domains}")
                    else:
                        result_instruction = f"[ë‹¤ì¤‘ ì—”í‹°í‹°: {', '.join(entity_counts)} - ìœ í˜•ë³„ ë³„ë„ í‘œ]"
                else:
                    row_count = sql_result.row_count if sql_result and hasattr(sql_result, 'row_count') else 0
                    result_instruction = f"[{row_count}ê±´ ì „ì²´ í‘œë¡œ ì¶œë ¥]" if row_count > 0 else ""

                # ë¹„êµ ë¶„ì„ ì§€ì¹¨ - ê°„ì†Œí™”
                comparison_instruction = ""
                if query_subtype == "comparison":
                    structured_keywords = state.get("structured_keywords", {})
                    comparison_targets = structured_keywords.get("filter", []) if structured_keywords else []
                    targets = ', '.join(comparison_targets) if comparison_targets else 'ì»¨í…ìŠ¤íŠ¸ ì°¸ì¡°'
                    comparison_instruction = f"[ë¹„êµ ë¶„ì„: {targets}]"

                # Phase 95: ê·¸ë˜í”„ ê´€ê³„ ì •ë³´ ì¶”ê°€
                # Phase 103.2: graph_context ì¤‘ë³µ ë°©ì§€ - contextì— ì´ë¯¸ RAG ì •ë³´ í¬í•¨
                rag_results = state.get("rag_results", [])
                # graph_context = _build_graph_context_for_prompt(rag_results)  # ì¤‘ë³µ ì œê±°
                # if graph_context:
                #     logger.info(f"Phase 95: ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ë¨ ({len(rag_results)}ê±´ RAG ê²°ê³¼ì—ì„œ)")

                user_prompt = f"""## ì»¨í…ìŠ¤íŠ¸
{context}
{result_instruction}{comparison_instruction}

## ì§ˆë¬¸
{query}"""

            # Phase 52: subtypeë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            # SQL ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì¥ë¹„ ì¶”ì²œ ë“±ì€ í‘œë¡œ ë³´ì—¬ì¤˜ì•¼ í•¨)
            has_sql_results = (
                (sql_result and sql_result.row_count > 0) or
                (multi_sql_results and any(r.row_count > 0 for r in multi_sql_results.values() if r.success))
            )

            # Phase 62/69/86: ì¶”ì²œ ì¿¼ë¦¬ ë¶„ê¸° (ê¸°ìˆ ë¶„ë¥˜ vs í˜‘ì—… ê¸°ê´€ vs ì¥ë¹„)
            if query_subtype == "recommendation":
                # Phase 69: í˜‘ì—… ê¸°ê´€ ì¶”ì²œ ê°ì§€
                is_collaboration = any(kw in query for kw in COLLABORATION_KEYWORDS)
                is_tech_classification = "ë¶„ë¥˜" in query or "tech" in entity_types
                # Phase 86: ì¥ë¹„ ì¶”ì²œ ê°ì§€ - entity_typesì— equipì´ ìˆê±°ë‚˜ ì¥ë¹„ ê´€ë ¨ í‚¤ì›Œë“œ
                is_equipment = "equip" in entity_types or any(
                    kw in query for kw in ["ì¥ë¹„", "ì¸¡ì •", "ì‹œí—˜ê¸°", "ë¶„ì„ê¸°", "equipment"]
                )

                if is_collaboration and not is_tech_classification and not is_equipment:
                    selected_prompt = COLLABORATION_PROMPT
                    logger.info(f"Phase 69: í˜‘ì—… ê¸°ê´€ ì¶”ì²œ ì¿¼ë¦¬ - COLLABORATION_PROMPT ì‚¬ìš© (SQLê²°ê³¼: {has_sql_results})")
                elif is_equipment and not is_tech_classification:
                    # Phase 86: ì¥ë¹„ ì¶”ì²œ
                    selected_prompt = EQUIPMENT_PROMPT
                    logger.info(f"Phase 86: ì¥ë¹„ ì¶”ì²œ ì¿¼ë¦¬ - EQUIPMENT_PROMPT ì‚¬ìš© (SQLê²°ê³¼: {has_sql_results})")
                else:
                    selected_prompt = RECOMMENDATION_PROMPT
                    logger.info(f"Phase 62: ê¸°ìˆ ë¶„ë¥˜ ì¶”ì²œ ì¿¼ë¦¬ - RECOMMENDATION_PROMPT ì‚¬ìš© (SQLê²°ê³¼: {has_sql_results})")
            elif query_subtype in SUBTYPE_PROMPTS:
                selected_prompt = SYSTEM_PROMPT + "\n\n## ì¶”ê°€ ì§€ì¹¨\n" + SUBTYPE_PROMPTS[query_subtype]
                logger.info(f"{query_subtype} ì¿¼ë¦¬ - ì¶”ê°€ ì§€ì¹¨ ì ìš©")
            else:
                selected_prompt = SYSTEM_PROMPT
                if has_sql_results:
                    logger.info(f"SQL ê²°ê³¼ {sql_result.row_count if sql_result else 0}ê±´ - SYSTEM_PROMPT ì‚¬ìš© (í‘œ ì¶œë ¥)")

            # Phase 54/70/73.2/92: ë‹¤ì¤‘ ì—”í‹°í‹°/ë„ë©”ì¸ ëŒ€ì‘ - max_tokens ë™ì  ì¡°ì •
            is_collaboration = query_subtype == "recommendation" and any(
                kw in query for kw in ["í˜‘ì—…", "í˜‘ë ¥", "íŒŒíŠ¸ë„ˆ", "ê³µë™ì—°êµ¬"]
            )
            is_nationality_ranking = query_subtype == "nationality_ranking"
            # Phase 92: ìš°ëŒ€/ê°ì  ì •ë³´ëŠ” ìš°ëŒ€ í‘œ + ê°ì  í‘œ + ìš”ì•½ í•„ìš”
            is_evalp_pref = query_subtype == "evalp_pref" or any(
                kw in query for kw in ["ìš°ëŒ€", "ê°ì ", "ê°€ì ", "ìš°ëŒ€ê°ì "]
            )

            if multi_sql_results and len(multi_sql_results) > 1:
                response_max_tokens = 2048  # ë‹¤ì¤‘ ì—”í‹°í‹°: í‘œ ì—¬ëŸ¬ ê°œ + ì†Œê²°
            elif is_collaboration:
                response_max_tokens = 3072  # Phase 70: ë‹¤ì¤‘ ë„ë©”ì¸ í˜‘ì—… ì¶”ì²œ (í‘œ2ê°œ+ì´í‰)
            elif is_nationality_ranking:
                response_max_tokens = 2048  # Phase 73.2: ìêµ­ í‘œ + íƒ€êµ­ í‘œ + ì¸ì‚¬ì´íŠ¸
            elif is_evalp_pref:
                response_max_tokens = 4096  # Phase 92: ìš°ëŒ€ í‘œ + ê°ì  í‘œ + ìš”ì•½ (3072â†’4096 ì¦ê°€)
            else:
                response_max_tokens = 1024  # ë‹¨ì¼ ì—”í‹°í‹°: ê¸°ì¡´ ìœ ì§€

            # Phase 92.1: ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
            logger.info(f"Phase 92 ë””ë²„ê¹…: query_subtype={query_subtype}, is_evalp_pref={is_evalp_pref}, max_tokens={response_max_tokens}")

            # Phase 90: ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            # sources ì¶”ì¶œ: sql_result ë° multi_sql_resultsì—ì„œ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            context_sources = []
            if sql_result and hasattr(sql_result, 'row_count') and sql_result.row_count > 0:
                context_sources.append({
                    'type': 'sql',
                    'score': 1.0,  # SQL ê²°ê³¼ëŠ” ì‹ ë¢°ë„ ë†’ìŒ
                    'cross_validated': True
                })
            if multi_sql_results:
                for entity_type, result in multi_sql_results.items():
                    if result.success and result.row_count > 0:
                        context_sources.append({
                            'type': f'sql_{entity_type}',
                            'score': 1.0,
                            'cross_validated': True
                        })

            # RAG ì†ŒìŠ¤ ì¶”ì¶œ (stateì—ì„œ)
            rag_results = state.get("rag_results", [])
            for rag_item in rag_results:
                if isinstance(rag_item, dict):
                    context_sources.append({
                        'type': rag_item.get('source', 'rag'),
                        'score': rag_item.get('score', 0.5),
                        'cross_validated': rag_item.get('cross_validated', False)
                    })

            context_quality = _calculate_context_quality(context, context_sources)
            logger.info(f"Phase 90: ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ = {context_quality:.2f} (ì†ŒìŠ¤ {len(context_sources)}ê°œ)")

            # í’ˆì§ˆ ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ê²½ê³  ë¡œê·¸
            if context_quality < 0.3:
                logger.warning(f"Phase 90: ë‚®ì€ ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ({context_quality:.2f}) - í™˜ê° ìœ„í—˜ ì£¼ì˜")

            # ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ ì ìš© (ê³µê³µ AX API)
            level = state.get("level", "ì¼ë°˜ì¸")
            level_prompt = LEVEL_PROMPTS.get(level, LEVEL_PROMPTS["ì¼ë°˜ì¸"])
            # Phase 102: ìì²´ ì§€ì‹ ê¸ˆì§€ ê·œì¹™ + ë ˆë²¨ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©
            final_prompt = f"{selected_prompt}\n\n{NO_HALLUCINATION_RULE}\n\n## ë‹µë³€ ìˆ˜ì¤€ ì§€ì¹¨\n{level_prompt}"
            logger.info(f"ë¦¬í„°ëŸ¬ì‹œ ë ˆë²¨ ì ìš©: {level}, ìì²´ ì§€ì‹ ê¸ˆì§€ ê·œì¹™ ì¶”ê°€")

            response = llm.generate(
                prompt=user_prompt,
                system_prompt=final_prompt,
                max_tokens=response_max_tokens,
                temperature=0.3
            )

        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        new_messages = [
            ChatMessage(role="user", content=query),
            ChatMessage(role="assistant", content=response)
        ]

        logger.info(f"ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response)}ì, ì‹ ë¢°ë„: {context_quality:.2f}")

        return {
            **state,
            "response": response,
            "context_quality": context_quality,  # Phase 102: ì‹ ë¢°ë„ ì ìˆ˜ ë°˜í™˜
            "conversation_history": new_messages
        }

    except Exception as e:
        logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        error_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

        return {
            **state,
            "response": error_response,
            "error": str(e),
            "conversation_history": [
                ChatMessage(role="user", content=query),
                ChatMessage(role="assistant", content=error_response)
            ]
        }
